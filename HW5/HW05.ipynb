{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AFEKWoh3p1Mv"
      },
      "source": [
        "# Homework Description\n",
        "- English to Chinese (Traditional) Translation\n",
        "  - Input: an English sentence         (e.g.\t\ttom is a student .)\n",
        "  - Output: the Chinese translation  (e.g. \t\t湯姆 是 個 學生 。)\n",
        "\n",
        "- TODO\n",
        "    - Train a simple RNN seq2seq to acheive translation\n",
        "    - Switch to transformer model to boost performance\n",
        "    - Apply Back-translation to furthur boost performance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Vf1Q79XPQ3D",
        "outputId": "6bc99387-e873-4bbf-9d81-1706904df370"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tue Apr  5 05:31:47 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 470.103.01   Driver Version: 470.103.01   CUDA Version: 11.4     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  NVIDIA GeForce ...  Off  | 00000000:01:00.0 Off |                  N/A |\n",
            "|  0%   45C    P8    11W / 275W |    202MiB / 11175MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|    0   N/A  N/A      1162      G   /usr/lib/xorg/Xorg                 35MiB |\n",
            "|    0   N/A  N/A      1722      G   /usr/lib/xorg/Xorg                112MiB |\n",
            "|    0   N/A  N/A      1849      G   /usr/bin/gnome-shell               21MiB |\n",
            "|    0   N/A  N/A      2324      G   ...RendererForSitePerProcess       19MiB |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "59neB_Sxp5Ub"
      },
      "source": [
        "# Download and import required packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rRlFbfFRpZYT",
        "outputId": "213ea67f-5983-4b20-ca76-f8730309ab2d"
      },
      "outputs": [],
      "source": [
        "# !pip install 'torch>=1.6.0' editdistance matplotlib sacrebleu sacremoses sentencepiece tqdm wandb\n",
        "# !pip install --upgrade jupyter ipywidgets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fSksMTdmp-Wt",
        "outputId": "34655423-fe36-4bbd-fd7a-472ab49d3b6e"
      },
      "outputs": [],
      "source": [
        "# !git clone https://github.com/pytorch/fairseq.git\n",
        "# !cd fairseq && git checkout 9a1c497\n",
        "# !pip install --upgrade ./fairseq/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "uRLTiuIuqGNc"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import pdb\n",
        "import pprint\n",
        "import logging\n",
        "import os\n",
        "import random\n",
        "import seaborn as sns\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils import data\n",
        "import numpy as np\n",
        "import tqdm.auto as tqdm\n",
        "from pathlib import Path\n",
        "from argparse import Namespace\n",
        "from fairseq import utils\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0n07Za1XqJzA"
      },
      "source": [
        "# Fix random seed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "xllxxyWxqI7s"
      },
      "outputs": [],
      "source": [
        "seed = 10942178\n",
        "random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)  \n",
        "np.random.seed(seed)  \n",
        "torch.backends.cudnn.benchmark = False\n",
        "torch.backends.cudnn.deterministic = True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N5ORDJ-2qdYw"
      },
      "source": [
        "# Dataset\n",
        "\n",
        "## En-Zh Bilingual Parallel Corpus\n",
        "* [TED2020](#reimers-2020-multilingual-sentence-bert)\n",
        "    - Raw: 398,066 (sentences)   \n",
        "    - Processed: 393,980 (sentences)\n",
        "    \n",
        "\n",
        "## Testdata\n",
        "- Size: 4,000 (sentences)\n",
        "- **Chinese translation is undisclosed. The provided (.zh) file is psuedo translation, each line is a '。'**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GQw2mY4Dqkzd"
      },
      "source": [
        "## Dataset Download"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SXT42xQtqijD",
        "outputId": "3b09f268-4e1e-4bc9-d42f-e20c68b38017"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "raw.en\n",
            "raw.zh\n",
            "test/\n",
            "test/test.zh\n",
            "test/test.en\n"
          ]
        }
      ],
      "source": [
        "data_dir = './DATA/rawdata'\n",
        "dataset_name = 'ted2020'\n",
        "urls = (\n",
        "    \"https://github.com/yuhsinchan/ML2022-HW5Dataset/releases/download/v1.0.2/ted2020.tgz\",\n",
        "    \"https://github.com/yuhsinchan/ML2022-HW5Dataset/releases/download/v1.0.2/test.tgz\",\n",
        ")\n",
        "file_names = (\n",
        "    'ted2020.tgz', # train & dev\n",
        "    'test.tgz', # test\n",
        ")\n",
        "prefix = Path(data_dir).absolute() / dataset_name\n",
        "\n",
        "prefix.mkdir(parents=True, exist_ok=True)\n",
        "for u, f in zip(urls, file_names):\n",
        "    path = prefix/f\n",
        "    if not path.exists():\n",
        "        !wget {u} -O {path}\n",
        "    if path.suffix == \".tgz\":\n",
        "        !tar -xvf {path} -C {prefix}\n",
        "    elif path.suffix == \".zip\":\n",
        "        !unzip -o {path} -d {prefix}\n",
        "!mv {prefix/'raw.en'} {prefix/'train_dev.raw.en'}\n",
        "!mv {prefix/'raw.zh'} {prefix/'train_dev.raw.zh'}\n",
        "!mv {prefix/'test/test.en'} {prefix/'test.raw.en'}\n",
        "!mv {prefix/'test/test.zh'} {prefix/'test.raw.zh'}\n",
        "!rm -rf {prefix/'test'}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YLkJwNiFrIwZ"
      },
      "source": [
        "## Language"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "_uJYkCncrKJb"
      },
      "outputs": [],
      "source": [
        "src_lang = 'en'\n",
        "tgt_lang = 'zh'\n",
        "\n",
        "data_prefix = f'{prefix}/train_dev.raw'\n",
        "test_prefix = f'{prefix}/test.raw'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0t2CPt1brOT3",
        "outputId": "14cd34e0-c8cb-4653-84c3-29de187d201a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Thank you so much, Chris.\n",
            "And it's truly a great honor to have the opportunity to come to this stage twice; I'm extremely grateful.\n",
            "I have been blown away by this conference, and I want to thank all of you for the many nice comments about what I had to say the other night.\n",
            "And I say that sincerely, partly because  I need that.\n",
            "Put yourselves in my position.\n",
            "非常謝謝你，克里斯。能有這個機會第二度踏上這個演講台\n",
            "真是一大榮幸。我非常感激。\n",
            "這個研討會給我留下了極為深刻的印象，我想感謝大家 對我之前演講的好評。\n",
            "我是由衷的想這麼說，有部份原因是因為 —— 我真的有需要!\n",
            "請你們設身處地為我想一想！\n"
          ]
        }
      ],
      "source": [
        "!head {data_prefix+'.'+src_lang} -n 5\n",
        "!head {data_prefix+'.'+tgt_lang} -n 5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pRoE9UK7r1gY"
      },
      "source": [
        "## Preprocess files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "3tzFwtnFrle3"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "def strQ2B(ustring):\n",
        "    \"\"\"Full width -> half width\"\"\"\n",
        "    # reference:https://ithelp.ithome.com.tw/articles/10233122\n",
        "    ss = []\n",
        "    for s in ustring:\n",
        "        rstring = \"\"\n",
        "        for uchar in s:\n",
        "            inside_code = ord(uchar)\n",
        "            if inside_code == 12288:  # Full width space: direct conversion\n",
        "                inside_code = 32\n",
        "            elif (inside_code >= 65281 and inside_code <= 65374):  # Full width chars (except space) conversion\n",
        "                inside_code -= 65248\n",
        "            rstring += chr(inside_code)\n",
        "        ss.append(rstring)\n",
        "    return ''.join(ss)\n",
        "                \n",
        "def clean_s(s, lang):\n",
        "    if lang == 'en':\n",
        "        s = re.sub(r\"\\([^()]*\\)\", \"\", s) # remove ([text])\n",
        "        s = s.replace('-', '') # remove '-'\n",
        "        s = re.sub('([.,;!?()\\\"])', r' \\1 ', s) # keep punctuation\n",
        "    elif lang == 'zh':\n",
        "        s = strQ2B(s) # Q2B\n",
        "        s = re.sub(r\"\\([^()]*\\)\", \"\", s) # remove ([text])\n",
        "        s = s.replace(' ', '')\n",
        "        s = s.replace('—', '')\n",
        "        s = s.replace('“', '\"')\n",
        "        s = s.replace('”', '\"')\n",
        "        s = s.replace('_', '')\n",
        "        s = re.sub('([。,;!?()\\\"~「」])', r' \\1 ', s) # keep punctuation\n",
        "    s = ' '.join(s.strip().split())\n",
        "    return s\n",
        "\n",
        "def len_s(s, lang):\n",
        "    if lang == 'zh':\n",
        "        return len(s)\n",
        "    return len(s.split())\n",
        "\n",
        "def clean_corpus(prefix, l1, l2, ratio=9, max_len=1000, min_len=1):\n",
        "    if Path(f'{prefix}.clean.{l1}').exists() and Path(f'{prefix}.clean.{l2}').exists():\n",
        "        print(f'{prefix}.clean.{l1} & {l2} exists. skipping clean.')\n",
        "        return\n",
        "    with open(f'{prefix}.{l1}', 'r') as l1_in_f:\n",
        "        with open(f'{prefix}.{l2}', 'r') as l2_in_f:\n",
        "            with open(f'{prefix}.clean.{l1}', 'w') as l1_out_f:\n",
        "                with open(f'{prefix}.clean.{l2}', 'w') as l2_out_f:\n",
        "                    for s1 in l1_in_f:\n",
        "                        s1 = s1.strip()\n",
        "                        s2 = l2_in_f.readline().strip()\n",
        "                        s1 = clean_s(s1, l1)\n",
        "                        s2 = clean_s(s2, l2)\n",
        "                        s1_len = len_s(s1, l1)\n",
        "                        s2_len = len_s(s2, l2)\n",
        "                        if min_len > 0: # remove short sentence\n",
        "                            if s1_len < min_len or s2_len < min_len:\n",
        "                                continue\n",
        "                        if max_len > 0: # remove long sentence\n",
        "                            if s1_len > max_len or s2_len > max_len:\n",
        "                                continue\n",
        "                        if ratio > 0: # remove by ratio of length\n",
        "                            if s1_len/s2_len > ratio or s2_len/s1_len > ratio:\n",
        "                                continue\n",
        "                        print(s1, file=l1_out_f)\n",
        "                        print(s2, file=l2_out_f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "h_i8b1PRr9Nf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/home/weiweichi/weichi/HW5/DATA/rawdata/ted2020/train_dev.raw.clean.en & zh exists. skipping clean.\n",
            "/home/weiweichi/weichi/HW5/DATA/rawdata/ted2020/test.raw.clean.en & zh exists. skipping clean.\n"
          ]
        }
      ],
      "source": [
        "clean_corpus(data_prefix, src_lang, tgt_lang)\n",
        "clean_corpus(test_prefix, src_lang, tgt_lang, ratio=-1, min_len=-1, max_len=-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gjT3XCy9r_rj",
        "outputId": "bdfb9b22-fc4d-4fb4-e244-647b903cea92"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Thank you so much , Chris .\n",
            "And it's truly a great honor to have the opportunity to come to this stage twice ; I'm extremely grateful .\n",
            "I have been blown away by this conference , and I want to thank all of you for the many nice comments about what I had to say the other night .\n",
            "And I say that sincerely , partly because I need that .\n",
            "Put yourselves in my position .\n",
            "非常謝謝你 , 克里斯 。 能有這個機會第二度踏上這個演講台\n",
            "真是一大榮幸 。 我非常感激 。\n",
            "這個研討會給我留下了極為深刻的印象 , 我想感謝大家對我之前演講的好評 。\n",
            "我是由衷的想這麼說 , 有部份原因是因為我真的有需要 !\n",
            "請你們設身處地為我想一想 !\n"
          ]
        }
      ],
      "source": [
        "!head {data_prefix+'.clean.'+src_lang} -n 5\n",
        "!head {data_prefix+'.clean.'+tgt_lang} -n 5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nKb4u67-sT_Z"
      },
      "source": [
        "## Split into train/valid"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "AuFKeDz3sGHL"
      },
      "outputs": [],
      "source": [
        "valid_ratio = 0.01 # 3000~4000 would suffice\n",
        "train_ratio = 1 - valid_ratio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "QR2NVldqsXyY"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train/valid splits exists. skipping split.\n"
          ]
        }
      ],
      "source": [
        "if (prefix/f'train.clean.{src_lang}').exists() \\\n",
        "and (prefix/f'train.clean.{tgt_lang}').exists() \\\n",
        "and (prefix/f'valid.clean.{src_lang}').exists() \\\n",
        "and (prefix/f'valid.clean.{tgt_lang}').exists():\n",
        "    print(f'train/valid splits exists. skipping split.')\n",
        "else:\n",
        "    line_num = sum(1 for line in open(f'{data_prefix}.clean.{src_lang}'))\n",
        "    labels = list(range(line_num))\n",
        "    random.shuffle(labels)\n",
        "    for lang in [src_lang, tgt_lang]:\n",
        "        train_f = open(os.path.join(data_dir, dataset_name, f'train.clean.{lang}'), 'w')\n",
        "        valid_f = open(os.path.join(data_dir, dataset_name, f'valid.clean.{lang}'), 'w')\n",
        "        count = 0\n",
        "        for line in open(f'{data_prefix}.clean.{lang}', 'r'):\n",
        "            if labels[count]/line_num < train_ratio:\n",
        "                train_f.write(line)\n",
        "            else:\n",
        "                valid_f.write(line)\n",
        "            count += 1\n",
        "        train_f.close()\n",
        "        valid_f.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n1rwQysTsdJq"
      },
      "source": [
        "## Subword Units \n",
        "Out of vocabulary (OOV) has been a major problem in machine translation. This can be alleviated by using subword units.\n",
        "- We will use the [sentencepiece](#kudo-richardson-2018-sentencepiece) package\n",
        "- select 'unigram' or 'byte-pair encoding (BPE)' algorithm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "Ecwllsa7sZRA"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/home/weiweichi/weichi/HW5/DATA/rawdata/ted2020/spm8000.model exists. skipping spm_train.\n"
          ]
        }
      ],
      "source": [
        "import sentencepiece as spm\n",
        "vocab_size = 8000\n",
        "if (prefix/f'spm{vocab_size}.model').exists():\n",
        "    print(f'{prefix}/spm{vocab_size}.model exists. skipping spm_train.')\n",
        "else:\n",
        "    spm.SentencePieceTrainer.train(\n",
        "        input=','.join([f'{prefix}/train.clean.{src_lang}',\n",
        "                        f'{prefix}/valid.clean.{src_lang}',\n",
        "                        f'{prefix}/train.clean.{tgt_lang}',\n",
        "                        f'{prefix}/valid.clean.{tgt_lang}']),\n",
        "        model_prefix=prefix/f'spm{vocab_size}',\n",
        "        vocab_size=vocab_size,\n",
        "        character_coverage=1,\n",
        "        model_type='unigram', # 'bpe' works as well\n",
        "        input_sentence_size=1e6,\n",
        "        shuffle_input_sentence=True,\n",
        "        normalization_rule_name='nmt_nfkc_cf',\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "lQPRNldqse_V"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/home/weiweichi/weichi/HW5/DATA/rawdata/ted2020/train.en exists. skipping spm_encode.\n",
            "/home/weiweichi/weichi/HW5/DATA/rawdata/ted2020/train.zh exists. skipping spm_encode.\n",
            "/home/weiweichi/weichi/HW5/DATA/rawdata/ted2020/valid.en exists. skipping spm_encode.\n",
            "/home/weiweichi/weichi/HW5/DATA/rawdata/ted2020/valid.zh exists. skipping spm_encode.\n",
            "/home/weiweichi/weichi/HW5/DATA/rawdata/ted2020/test.en exists. skipping spm_encode.\n",
            "/home/weiweichi/weichi/HW5/DATA/rawdata/ted2020/test.zh exists. skipping spm_encode.\n"
          ]
        }
      ],
      "source": [
        "spm_model = spm.SentencePieceProcessor(model_file=str(prefix/f'spm{vocab_size}.model'))\n",
        "in_tag = {\n",
        "    'train': 'train.clean',\n",
        "    'valid': 'valid.clean',\n",
        "    'test': 'test.raw.clean',\n",
        "}\n",
        "for split in ['train', 'valid', 'test']:\n",
        "    for lang in [src_lang, tgt_lang]:\n",
        "        out_path = prefix/f'{split}.{lang}'\n",
        "        if out_path.exists():\n",
        "            print(f\"{out_path} exists. skipping spm_encode.\")\n",
        "        else:\n",
        "            with open(prefix/f'{split}.{lang}', 'w') as out_f:\n",
        "                with open(prefix/f'{in_tag[split]}.{lang}', 'r') as in_f:\n",
        "                    for line in in_f:\n",
        "                        line = line.strip()\n",
        "                        tok = spm_model.encode(line, out_type=str)\n",
        "                        print(' '.join(tok), file=out_f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4j6lXHjAsjXa",
        "outputId": "4a86a8a6-c461-441d-a933-d06ab071dc46"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "▁thank ▁you ▁so ▁much ▁, ▁chris ▁.\n",
            "▁and ▁it ' s ▁ t ru ly ▁a ▁great ▁ho n or ▁to ▁have ▁the ▁ op port un ity ▁to ▁come ▁to ▁this ▁st age ▁ t wi ce ▁; ▁i ' m ▁ex t re me ly ▁gr ate ful ▁.\n",
            "▁i ▁have ▁been ▁ bl ow n ▁away ▁by ▁this ▁con fer ence ▁, ▁and ▁i ▁want ▁to ▁thank ▁all ▁of ▁you ▁for ▁the ▁many ▁ ni ce ▁ com ment s ▁about ▁what ▁i ▁had ▁to ▁say ▁the ▁other ▁night ▁.\n",
            "▁and ▁i ▁say ▁that ▁since re ly ▁, ▁part ly ▁because ▁i ▁need ▁that ▁.\n",
            "▁put ▁your s el ve s ▁in ▁my ▁po s ition ▁.\n",
            "▁ 非常 謝 謝 你 ▁, ▁ 克 里 斯 ▁。 ▁ 能 有 這個 機會 第二 度 踏 上 這個 演講 台\n",
            "▁ 真 是 一 大 榮 幸 ▁。 ▁我 非常 感 激 ▁。\n",
            "▁這個 研 討 會 給我 留 下 了 極 為 深 刻 的 印 象 ▁, ▁我想 感 謝 大家 對我 之前 演講 的 好 評 ▁。\n",
            "▁我 是由 衷 的 想 這麼 說 ▁, ▁有 部份 原因 是因為 我 真的 有 需要 ▁!\n",
            "▁ 請 你們 設 身 處 地 為 我想 一 想 ▁!\n"
          ]
        }
      ],
      "source": [
        "!head {data_dir+'/'+dataset_name+'/train.'+src_lang} -n 5\n",
        "!head {data_dir+'/'+dataset_name+'/train.'+tgt_lang} -n 5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "59si_C0Wsms7"
      },
      "source": [
        "## Binarize the data with fairseq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w-cHVLSpsknh",
        "outputId": "3447b375-ab55-4508-8fdd-b660c3f91ca0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DATA/data-bin/ted2020 exists, will not overwrite!\n"
          ]
        }
      ],
      "source": [
        "binpath = Path('./DATA/data-bin', dataset_name)\n",
        "if binpath.exists():\n",
        "    print(binpath, \"exists, will not overwrite!\")\n",
        "else:\n",
        "    !python3 -m fairseq_cli.preprocess \\\n",
        "        --source-lang {src_lang}\\\n",
        "        --target-lang {tgt_lang}\\\n",
        "        --trainpref {prefix/'train'}\\\n",
        "        --validpref {prefix/'valid'}\\\n",
        "        --testpref {prefix/'test'}\\\n",
        "        --destdir {binpath}\\\n",
        "        --joined-dictionary\\\n",
        "        --workers 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "szMuH1SWLPWA"
      },
      "source": [
        "# Configuration for experiments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "5Luz3_tVLUxs"
      },
      "outputs": [],
      "source": [
        "config = Namespace(\n",
        "    datadir = \"./DATA/data-bin/ted2020\",\n",
        "    savedir = \"./checkpoints/transformer-bt\",\n",
        "    source_lang = \"zh\",\n",
        "    target_lang = \"en\",\n",
        "    \n",
        "    # cpu threads when fetching & processing data.\n",
        "    num_workers=2,  \n",
        "    # batch size in terms of tokens. gradient accumulation increases the effective batchsize.\n",
        "    max_tokens=8192,\n",
        "    accum_steps=2,\n",
        "    \n",
        "    # the lr s calculated from Noam lr scheduler. you can tune the maximum lr by this factor.\n",
        "    lr_factor=2.,\n",
        "    lr_warmup=4000,\n",
        "    \n",
        "    # clipping gradient norm helps alleviate gradient exploding\n",
        "    clip_norm=1.0,\n",
        "    \n",
        "    # maximum epochs for training\n",
        "    max_epoch=30,\n",
        "    start_epoch=1,\n",
        "    \n",
        "    # beam size for beam search\n",
        "    beam=5, \n",
        "    # generate sequences of maximum length ax + b, where x is the source length\n",
        "    max_len_a=1.2, \n",
        "    max_len_b=10, \n",
        "    # when decoding, post process sentence by removing sentencepiece symbols and jieba tokenization.\n",
        "    post_process = \"sentencepiece\",\n",
        "    \n",
        "    # checkpoints\n",
        "    keep_last_epochs=5,\n",
        "    resume=None, # if resume from checkpoint name (under config.savedir)\n",
        "    \n",
        "    # logging\n",
        "    use_wandb=False,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cjrJFvyQLg86"
      },
      "source": [
        "# Logging\n",
        "- logging package logs ordinary messages\n",
        "- wandb logs the loss, bleu, etc. in the training process"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "-ZiMyDWALbDk"
      },
      "outputs": [],
      "source": [
        "logging.basicConfig(\n",
        "    format=\"%(asctime)s | %(levelname)s | %(name)s | %(message)s\",\n",
        "    datefmt=\"%Y-%m-%d %H:%M:%S\",\n",
        "    level=\"INFO\", # \"DEBUG\" \"WARNING\" \"ERROR\"\n",
        "    stream=sys.stdout,\n",
        ")\n",
        "proj = \"hw5.seq2seq\"\n",
        "logger = logging.getLogger(proj)\n",
        "if config.use_wandb:\n",
        "    import wandb\n",
        "    wandb.init(project=proj, name=Path(config.savedir).stem, config=config)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BNoSkK45Lmqc"
      },
      "source": [
        "# CUDA Environments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oqrsbmcoLqMl",
        "outputId": "b40fe6d7-bd8e-4cf2-a29f-e01442f7cf8a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-04-05 05:31:57 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************\n",
            "2022-04-05 05:31:57 | INFO | fairseq.utils | rank   0: capabilities =  6.1  ; total memory = 10.913 GB ; name = NVIDIA GeForce GTX 1080 Ti              \n",
            "2022-04-05 05:31:57 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************\n"
          ]
        }
      ],
      "source": [
        "cuda_env = utils.CudaEnvironment()\n",
        "utils.CudaEnvironment.pretty_print_cuda_env_list([cuda_env])\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TbJuBIHLLt2D"
      },
      "source": [
        "# Dataloading"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oOpG4EBRLwe_"
      },
      "source": [
        "## We borrow the TranslationTask from fairseq\n",
        "* used to load the binarized data created above\n",
        "* well-implemented data iterator (dataloader)\n",
        "* built-in task.source_dictionary and task.target_dictionary are also handy\n",
        "* well-implemented beach search decoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3gSEy1uFLvVs",
        "outputId": "a7a4e866-1595-4d61-e680-0ff6543decd6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-04-05 05:31:57 | INFO | fairseq.tasks.translation | [zh] dictionary: 7992 types\n",
            "2022-04-05 05:31:57 | INFO | fairseq.tasks.translation | [en] dictionary: 7992 types\n"
          ]
        }
      ],
      "source": [
        "from fairseq.tasks.translation import TranslationConfig, TranslationTask\n",
        "\n",
        "## setup task\n",
        "task_cfg = TranslationConfig(\n",
        "    data=config.datadir,\n",
        "    source_lang=config.source_lang,\n",
        "    target_lang=config.target_lang,\n",
        "    train_subset=\"train\",\n",
        "    required_seq_len_multiple=8,\n",
        "    dataset_impl=\"mmap\",\n",
        "    upsample_primary=1,\n",
        ")\n",
        "task = TranslationTask.setup_task(task_cfg)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mR7Bhov7L4IU",
        "outputId": "b5d07fcc-7c94-47de-8f9d-4bd79ba7e924"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-04-05 05:31:57 | INFO | hw5.seq2seq | loading data for epoch 1\n",
            "2022-04-05 05:31:57 | INFO | fairseq.data.data_utils | loaded 390,041 examples from: ./DATA/data-bin/ted2020/train.en-zh.zh\n",
            "2022-04-05 05:31:57 | INFO | fairseq.data.data_utils | loaded 390,041 examples from: ./DATA/data-bin/ted2020/train.en-zh.en\n",
            "2022-04-05 05:31:57 | INFO | fairseq.tasks.translation | ./DATA/data-bin/ted2020 train zh-en 390041 examples\n",
            "2022-04-05 05:31:57 | INFO | fairseq.data.data_utils | loaded 3,939 examples from: ./DATA/data-bin/ted2020/valid.en-zh.zh\n",
            "2022-04-05 05:31:57 | INFO | fairseq.data.data_utils | loaded 3,939 examples from: ./DATA/data-bin/ted2020/valid.en-zh.en\n",
            "2022-04-05 05:31:57 | INFO | fairseq.tasks.translation | ./DATA/data-bin/ted2020 valid zh-en 3939 examples\n"
          ]
        }
      ],
      "source": [
        "logger.info(\"loading data for epoch 1\")\n",
        "task.load_dataset(split=\"train\", epoch=1, combine=True) # combine if you have back-translation data.\n",
        "task.load_dataset(split=\"valid\", epoch=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P0BCEm_9L6ig",
        "outputId": "e03fdcf3-d4c9-4710-dbff-e94e0cce91a2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'id': 1,\n",
            " 'source': tensor([  53, 3134, 3107,   34,  408, 1223, 3895,  670,    9, 1038,  498,  148,\n",
            "        1689,  364,  129, 1050, 1103,   34,  408,  158,  607, 3268,  306,    9,\n",
            "        1105,    2]),\n",
            " 'target': tensor([  35,   22,  440,   27,    5,  850,  261,  172,    6,   29,  800,    6,\n",
            "         184,  164,   99, 1178,  374,  804,  257,   41,    5,  313,  868,   42,\n",
            "          27,   61, 1836,   18,  184, 1147, 1404,   21,    6,    6,  320,    7,\n",
            "           2])}\n",
            "'Source: 我們培植了一些果蠅它們的腦部被隨機地安置了一些可以光驅動的細胞'\n",
            "('Target: so we bred flies whose brains were more or less randomly peppered '\n",
            " 'with cells that were light addressable .')\n"
          ]
        }
      ],
      "source": [
        "sample = task.dataset(\"valid\")[1]\n",
        "pprint.pprint(sample)\n",
        "pprint.pprint(\n",
        "    \"Source: \" + \\\n",
        "    task.source_dictionary.string(\n",
        "        sample['source'],\n",
        "        config.post_process,\n",
        "    )\n",
        ")\n",
        "pprint.pprint(\n",
        "    \"Target: \" + \\\n",
        "    task.target_dictionary.string(\n",
        "        sample['target'],\n",
        "        config.post_process,\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UcfCVa2FMBSE"
      },
      "source": [
        "# Dataset iterator"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yBvc-B_6MKZM"
      },
      "source": [
        "* Controls every batch to contain no more than N tokens, which optimizes GPU memory efficiency\n",
        "* Shuffles the training set for every epoch\n",
        "* Ignore sentences exceeding maximum length\n",
        "* Pad all sentences in a batch to the same length, which enables parallel computing by GPU\n",
        "* Add eos and shift one token\n",
        "    - teacher forcing: to train the model to predict the next token based on prefix, we feed the right shifted target sequence as the decoder input.\n",
        "    - generally, prepending bos to the target would do the job (as shown below)\n",
        "![seq2seq](https://i.imgur.com/0zeDyuI.png)\n",
        "    - in fairseq however, this is done by moving the eos token to the begining. Empirically, this has the same effect. For instance:\n",
        "    ```\n",
        "    # output target (target) and Decoder input (prev_output_tokens): \n",
        "                   eos = 2\n",
        "                target = 419,  711,  238,  888,  792,   60,  968,    8,    2\n",
        "    prev_output_tokens = 2,  419,  711,  238,  888,  792,   60,  968,    8\n",
        "    ```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OWFJFmCnMDXW",
        "outputId": "d5a62c5f-df9b-4e71-86ad-d27de323492d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-04-05 05:31:57 | WARNING | fairseq.tasks.fairseq_task | 2,565 samples have invalid sizes and will be skipped, max_positions=(20, 20), first few sample ids=[1811, 3245, 3729, 1898, 732, 226, 3630, 2905, 2594, 196]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'id': tensor([2001, 3666]),\n",
              " 'nsentences': 2,\n",
              " 'ntokens': 15,\n",
              " 'net_input': {'src_tokens': tensor([[   1,    5,  299, 1257,  843,  611,  413,    2],\n",
              "          [   1,   53,  968,  407,  177,  362,   33,    2]]),\n",
              "  'src_lengths': tensor([7, 7]),\n",
              "  'prev_output_tokens': tensor([[   2, 1166,  812,  542,  519,  538,    7,    1],\n",
              "          [   2,  151,  741,   22,  657,  718,   18,   33]])},\n",
              " 'target': tensor([[1166,  812,  542,  519,  538,    7,    2,    1],\n",
              "         [ 151,  741,   22,  657,  718,   18,   33,    2]])}"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def load_data_iterator(task, split, epoch=1, max_tokens=4000, num_workers=1, cached=True):\n",
        "    batch_iterator = task.get_batch_iterator(\n",
        "        dataset=task.dataset(split),\n",
        "        max_tokens=max_tokens,\n",
        "        max_sentences=None,\n",
        "        max_positions=utils.resolve_max_positions(\n",
        "            task.max_positions(),\n",
        "            max_tokens,\n",
        "        ),\n",
        "        ignore_invalid_inputs=True,\n",
        "        seed=seed,\n",
        "        num_workers=num_workers,\n",
        "        epoch=epoch,\n",
        "        disable_iterator_cache=not cached,\n",
        "        # Set this to False to speed up. However, if set to False, changing max_tokens beyond \n",
        "        # first call of this method has no effect. \n",
        "    )\n",
        "    return batch_iterator\n",
        "\n",
        "demo_epoch_obj = load_data_iterator(task, \"valid\", epoch=1, max_tokens=20, num_workers=1, cached=False)\n",
        "demo_iter = demo_epoch_obj.next_epoch_itr(shuffle=True)\n",
        "sample = next(demo_iter)\n",
        "sample"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p86K-0g7Me4M"
      },
      "source": [
        "* each batch is a python dict, with string key and Tensor value. Contents are described below:\n",
        "```python\n",
        "batch = {\n",
        "    \"id\": id, # id for each example \n",
        "    \"nsentences\": len(samples), # batch size (sentences)\n",
        "    \"ntokens\": ntokens, # batch size (tokens)\n",
        "    \"net_input\": {\n",
        "        \"src_tokens\": src_tokens, # sequence in source language\n",
        "        \"src_lengths\": src_lengths, # sequence length of each example before padding\n",
        "        \"prev_output_tokens\": prev_output_tokens, # right shifted target, as mentioned above.\n",
        "    },\n",
        "    \"target\": target, # target sequence\n",
        "}\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9EyDBE5ZMkFZ"
      },
      "source": [
        "# Model Architecture\n",
        "* We again inherit fairseq's encoder, decoder and model, so that in the testing phase we can directly leverage fairseq's beam search decoder."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "Hzh74qLIMfW_"
      },
      "outputs": [],
      "source": [
        "from fairseq.models import (\n",
        "    FairseqEncoder, \n",
        "    FairseqIncrementalDecoder,\n",
        "    FairseqEncoderDecoderModel\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UDAPmxjRNEEL"
      },
      "source": [
        "## Seq2Seq\n",
        "- Composed of **Encoder** and **Decoder**\n",
        "- Recieves inputs and pass to **Encoder** \n",
        "- Pass the outputs from **Encoder** to **Decoder**\n",
        "- **Decoder** will decode according to outputs of previous timesteps as well as **Encoder** outputs  \n",
        "- Once done decoding, return the **Decoder** outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "oRwKdLa0NEU6"
      },
      "outputs": [],
      "source": [
        "class Seq2Seq(FairseqEncoderDecoderModel):\n",
        "    def __init__(self, args, encoder, decoder):\n",
        "        super().__init__(encoder, decoder)\n",
        "        self.args = args\n",
        "    \n",
        "    def forward(\n",
        "        self,\n",
        "        src_tokens,\n",
        "        src_lengths,\n",
        "        prev_output_tokens,\n",
        "        return_all_hiddens: bool = True,\n",
        "    ):\n",
        "        \"\"\"\n",
        "        Run the forward pass for an encoder-decoder model.\n",
        "        \"\"\"\n",
        "        encoder_out = self.encoder(\n",
        "            src_tokens, src_lengths=src_lengths, return_all_hiddens=return_all_hiddens\n",
        "        )\n",
        "        logits, extra = self.decoder(\n",
        "            prev_output_tokens,\n",
        "            encoder_out=encoder_out,\n",
        "            src_lengths=src_lengths,\n",
        "            return_all_hiddens=return_all_hiddens,\n",
        "        )\n",
        "        return logits, extra"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zu3C2JfqNHzk"
      },
      "source": [
        "# Model Initialization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "nyI9FOx-NJ2m"
      },
      "outputs": [],
      "source": [
        "# # HINT: transformer architecture\n",
        "from fairseq.models.transformer import (\n",
        "    TransformerEncoder, \n",
        "    TransformerDecoder,\n",
        ")\n",
        "\n",
        "def build_model(args, task):\n",
        "    \"\"\" build a model instance based on hyperparameters \"\"\"\n",
        "    src_dict, tgt_dict = task.source_dictionary, task.target_dictionary\n",
        "\n",
        "    # token embeddings\n",
        "    encoder_embed_tokens = nn.Embedding(len(src_dict), args.encoder_embed_dim, src_dict.pad())\n",
        "    decoder_embed_tokens = nn.Embedding(len(tgt_dict), args.decoder_embed_dim, tgt_dict.pad())\n",
        "    \n",
        "    # encoder decoder\n",
        "    # HINT: TODO: switch to TransformerEncoder & TransformerDecoder\n",
        "    encoder = TransformerEncoder(args, src_dict, encoder_embed_tokens)\n",
        "    decoder = TransformerDecoder(args, tgt_dict, decoder_embed_tokens)\n",
        "\n",
        "    # sequence to sequence model\n",
        "    model = Seq2Seq(args, encoder, decoder)\n",
        "    \n",
        "    # initialization for seq2seq model is important, requires extra handling\n",
        "    def init_params(module):\n",
        "        from fairseq.modules import MultiheadAttention\n",
        "        if isinstance(module, nn.Linear):\n",
        "            module.weight.data.normal_(mean=0.0, std=0.02)\n",
        "            if module.bias is not None:\n",
        "                module.bias.data.zero_()\n",
        "        if isinstance(module, nn.Embedding):\n",
        "            module.weight.data.normal_(mean=0.0, std=0.02)\n",
        "            if module.padding_idx is not None:\n",
        "                module.weight.data[module.padding_idx].zero_()\n",
        "        if isinstance(module, MultiheadAttention):\n",
        "            module.q_proj.weight.data.normal_(mean=0.0, std=0.02)\n",
        "            module.k_proj.weight.data.normal_(mean=0.0, std=0.02)\n",
        "            module.v_proj.weight.data.normal_(mean=0.0, std=0.02)\n",
        "        if isinstance(module, nn.RNNBase):\n",
        "            for name, param in module.named_parameters():\n",
        "                if \"weight\" in name or \"bias\" in name:\n",
        "                    param.data.uniform_(-0.1, 0.1)\n",
        "            \n",
        "    # weight initialization\n",
        "    model.apply(init_params)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ce5n4eS7NQNy"
      },
      "source": [
        "## Architecture Related Configuration\n",
        "\n",
        "For strong baseline, please refer to the hyperparameters for *transformer-base* in Table 3 in [Attention is all you need](#vaswani2017)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "Cyn30VoGNT6N"
      },
      "outputs": [],
      "source": [
        "arch_args = Namespace(\n",
        "    encoder_embed_dim=512,\n",
        "    encoder_ffn_embed_dim=2048,\n",
        "    encoder_layers=6,\n",
        "    decoder_embed_dim=512,\n",
        "    decoder_ffn_embed_dim=2048,\n",
        "    decoder_layers=6,\n",
        "    share_decoder_input_output_embed=True,\n",
        "    dropout=0.1,\n",
        ")\n",
        "\n",
        "# HINT: these patches on parameters for Transformer\n",
        "def add_transformer_args(args):\n",
        "    args.encoder_attention_heads=8\n",
        "    args.encoder_normalize_before=True\n",
        "    \n",
        "    args.decoder_attention_heads=8\n",
        "    args.decoder_normalize_before=True\n",
        "    \n",
        "    args.activation_fn=\"relu\"\n",
        "    args.max_source_positions=1024\n",
        "    args.max_target_positions=1024\n",
        "    \n",
        "    # patches on default parameters for Transformer (those not set above)\n",
        "    from fairseq.models.transformer import base_architecture\n",
        "    base_architecture(arch_args)\n",
        "\n",
        "add_transformer_args(arch_args)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "Nbb76QLCNZZZ"
      },
      "outputs": [],
      "source": [
        "if config.use_wandb:\n",
        "    wandb.config.update(vars(arch_args))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ZWfxsCDNatH",
        "outputId": "ce69bfe3-52b7-4e6b-afb5-2b3a7ac37149"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-04-05 05:31:59 | INFO | hw5.seq2seq | Seq2Seq(\n",
            "  (encoder): TransformerEncoder(\n",
            "    (dropout_module): FairseqDropout()\n",
            "    (embed_tokens): Embedding(7992, 512, padding_idx=1)\n",
            "    (embed_positions): SinusoidalPositionalEmbedding()\n",
            "    (layers): ModuleList(\n",
            "      (0): TransformerEncoderLayer(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (1): TransformerEncoderLayer(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (2): TransformerEncoderLayer(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (3): TransformerEncoderLayer(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (4): TransformerEncoderLayer(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (5): TransformerEncoderLayer(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "    )\n",
            "    (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "  )\n",
            "  (decoder): TransformerDecoder(\n",
            "    (dropout_module): FairseqDropout()\n",
            "    (embed_tokens): Embedding(7992, 512, padding_idx=1)\n",
            "    (embed_positions): SinusoidalPositionalEmbedding()\n",
            "    (layers): ModuleList(\n",
            "      (0): TransformerDecoderLayer(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "        (encoder_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (1): TransformerDecoderLayer(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "        (encoder_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (2): TransformerDecoderLayer(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "        (encoder_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (3): TransformerDecoderLayer(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "        (encoder_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (4): TransformerDecoderLayer(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "        (encoder_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (5): TransformerDecoderLayer(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "        (encoder_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "    )\n",
            "    (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "    (output_projection): Linear(in_features=512, out_features=7992, bias=False)\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "model = build_model(arch_args, task)\n",
        "logger.info(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aHll7GRNNdqc"
      },
      "source": [
        "# Optimization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rUB9f1WCNgMH"
      },
      "source": [
        "## Loss: Label Smoothing Regularization\n",
        "* let the model learn to generate less concentrated distribution, and prevent over-confidence\n",
        "* sometimes the ground truth may not be the only answer. thus, when calculating loss, we reserve some probability for incorrect labels\n",
        "* avoids overfitting\n",
        "\n",
        "code [source](https://fairseq.readthedocs.io/en/latest/_modules/fairseq/criterions/label_smoothed_cross_entropy.html)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "IgspdJn0NdYF"
      },
      "outputs": [],
      "source": [
        "class LabelSmoothedCrossEntropyCriterion(nn.Module):\n",
        "    def __init__(self, smoothing, ignore_index=None, reduce=True):\n",
        "        super().__init__()\n",
        "        self.smoothing = smoothing\n",
        "        self.ignore_index = ignore_index\n",
        "        self.reduce = reduce\n",
        "    \n",
        "    def forward(self, lprobs, target):\n",
        "        if target.dim() == lprobs.dim() - 1:\n",
        "            target = target.unsqueeze(-1)\n",
        "        # nll: Negative log likelihood，the cross-entropy when target is one-hot. following line is same as F.nll_loss\n",
        "        nll_loss = -lprobs.gather(dim=-1, index=target)\n",
        "        #  reserve some probability for other labels. thus when calculating cross-entropy, \n",
        "        # equivalent to summing the log probs of all labels\n",
        "        smooth_loss = -lprobs.sum(dim=-1, keepdim=True)\n",
        "        if self.ignore_index is not None:\n",
        "            pad_mask = target.eq(self.ignore_index)\n",
        "            nll_loss.masked_fill_(pad_mask, 0.0)\n",
        "            smooth_loss.masked_fill_(pad_mask, 0.0)\n",
        "        else:\n",
        "            nll_loss = nll_loss.squeeze(-1)\n",
        "            smooth_loss = smooth_loss.squeeze(-1)\n",
        "        if self.reduce:\n",
        "            nll_loss = nll_loss.sum()\n",
        "            smooth_loss = smooth_loss.sum()\n",
        "        # when calculating cross-entropy, add the loss of other labels\n",
        "        eps_i = self.smoothing / lprobs.size(-1)\n",
        "        loss = (1.0 - self.smoothing) * nll_loss + eps_i * smooth_loss\n",
        "        return loss\n",
        "\n",
        "# generally, 0.1 is good enough\n",
        "criterion = LabelSmoothedCrossEntropyCriterion(\n",
        "    smoothing=0.1,\n",
        "    ignore_index=task.target_dictionary.pad(),\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aRalDto2NkJJ"
      },
      "source": [
        "## Optimizer: Adam + lr scheduling\n",
        "Inverse square root scheduling is important to the stability when training Transformer. It's later used on RNN as well.\n",
        "Update the learning rate according to the following equation. Linearly increase the first stage, then decay proportionally to the inverse square root of timestep.\n",
        "$$lrate = d_{\\text{model}}^{-0.5}\\cdot\\min({step\\_num}^{-0.5},{step\\_num}\\cdot{warmup\\_steps}^{-1.5})$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "sS7tQj1ROBYm"
      },
      "outputs": [],
      "source": [
        "def get_rate(d_model, step_num, warmup_step):\n",
        "    # TODO: Change lr from constant to the equation shown above\n",
        "    return d_model**(-0.5) * min(step_num ** (-0.5), step_num * warmup_step ** (-1.5))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "J8hoAjHPNkh3"
      },
      "outputs": [],
      "source": [
        "class NoamOpt:\n",
        "    \"Optim wrapper that implements rate.\"\n",
        "    def __init__(self, model_size, factor, warmup, optimizer):\n",
        "        self.optimizer = optimizer\n",
        "        self._step = 0\n",
        "        self.warmup = warmup\n",
        "        self.factor = factor\n",
        "        self.model_size = model_size\n",
        "        self._rate = 0\n",
        "        \n",
        "    @property\n",
        "    def param_groups(self):\n",
        "        return self.optimizer.param_groups\n",
        "        \n",
        "    def multiply_grads(self, c):\n",
        "        \"\"\"Multiplies grads by a constant *c*.\"\"\"                \n",
        "        for group in self.param_groups:\n",
        "            for p in group['params']:\n",
        "                if p.grad is not None:\n",
        "                    p.grad.data.mul_(c)\n",
        "        \n",
        "    def step(self):\n",
        "        \"Update parameters and rate\"\n",
        "        self._step += 1\n",
        "        rate = self.rate()\n",
        "        for p in self.param_groups:\n",
        "            p['lr'] = rate\n",
        "        self._rate = rate\n",
        "        self.optimizer.step()\n",
        "        \n",
        "    def rate(self, step = None):\n",
        "        \"Implement `lrate` above\"\n",
        "        if step is None:\n",
        "            step = self._step\n",
        "        return 0 if not step else self.factor * get_rate(self.model_size, step, self.warmup)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VFJlkOMONsc6"
      },
      "source": [
        "## Scheduling Visualized"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "A135fwPCNrQs",
        "outputId": "7074381b-f215-463a-da7d-3422dc7b675d"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "optimizer = NoamOpt(\n",
        "    model_size=arch_args.encoder_embed_dim, \n",
        "    factor=config.lr_factor, \n",
        "    warmup=config.lr_warmup, \n",
        "    optimizer=torch.optim.AdamW(model.parameters(), lr=0, betas=(0.9, 0.98), eps=1e-9, weight_decay=0.0001))\n",
        "plt.plot(np.arange(1, 100000), [optimizer.rate(i) for i in range(1, 100000)])\n",
        "plt.legend([f\"{optimizer.model_size}:{optimizer.warmup}\"])\n",
        "None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TOR0g-cVO5ZO"
      },
      "source": [
        "# Training Procedure"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f-0ZjbK3O8Iv"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "foal3xM1O404"
      },
      "outputs": [],
      "source": [
        "from fairseq.data import iterators\n",
        "from torch.cuda.amp import GradScaler, autocast\n",
        "\n",
        "def train_one_epoch(epoch_itr, model, task, criterion, optimizer, accum_steps=1):\n",
        "    itr = epoch_itr.next_epoch_itr(shuffle=True)\n",
        "    itr = iterators.GroupedIterator(itr, accum_steps) # gradient accumulation: update every accum_steps samples\n",
        "    \n",
        "    stats = {\"loss\": []}\n",
        "    scaler = GradScaler() # automatic mixed precision (amp) \n",
        "    \n",
        "    model.train()\n",
        "    progress = tqdm.tqdm(itr, desc=f\"train epoch {epoch_itr.epoch}\", leave=False)\n",
        "    for samples in progress:\n",
        "        model.zero_grad()\n",
        "        accum_loss = 0\n",
        "        sample_size = 0\n",
        "        # gradient accumulation: update every accum_steps samples\n",
        "        for i, sample in enumerate(samples):\n",
        "            if i == 1:\n",
        "                # emptying the CUDA cache after the first step can reduce the chance of OOM\n",
        "                torch.cuda.empty_cache()\n",
        "\n",
        "            sample = utils.move_to_cuda(sample, device=device)\n",
        "            target = sample[\"target\"]\n",
        "            sample_size_i = sample[\"ntokens\"]\n",
        "            sample_size += sample_size_i\n",
        "            \n",
        "            # mixed precision training\n",
        "            with autocast():\n",
        "                net_output = model.forward(**sample[\"net_input\"])\n",
        "                lprobs = F.log_softmax(net_output[0], -1)            \n",
        "                loss = criterion(lprobs.view(-1, lprobs.size(-1)), target.view(-1))\n",
        "                \n",
        "                # logging\n",
        "                accum_loss += loss.item()\n",
        "                # back-prop\n",
        "                scaler.scale(loss).backward()                \n",
        "        \n",
        "        scaler.unscale_(optimizer)\n",
        "        optimizer.multiply_grads(1 / (sample_size or 1.0)) # (sample_size or 1.0) handles the case of a zero gradient\n",
        "        gnorm = nn.utils.clip_grad_norm_(model.parameters(), config.clip_norm) # grad norm clipping prevents gradient exploding\n",
        "        \n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "        \n",
        "        # logging\n",
        "        loss_print = accum_loss/sample_size\n",
        "        stats[\"loss\"].append(loss_print)\n",
        "        progress.set_postfix(loss=loss_print)\n",
        "        if config.use_wandb:\n",
        "            wandb.log({\n",
        "                \"train/loss\": loss_print,\n",
        "                \"train/grad_norm\": gnorm.item(),\n",
        "                \"train/lr\": optimizer.rate(),\n",
        "                \"train/sample_size\": sample_size,\n",
        "            })\n",
        "        \n",
        "    loss_print = np.mean(stats[\"loss\"])\n",
        "    logger.info(f\"training loss: {loss_print:.4f}\")\n",
        "    return stats"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gt1lX3DRO_yU"
      },
      "source": [
        "## Validation & Inference\n",
        "To prevent overfitting, validation is required every epoch to validate the performance on unseen data.\n",
        "- the procedure is essensially same as training, with the addition of inference step\n",
        "- after validation we can save the model weights\n",
        "\n",
        "Validation loss alone cannot describe the actual performance of the model\n",
        "- Directly produce translation hypotheses based on current model, then calculate BLEU with the reference translation\n",
        "- We can also manually examine the hypotheses' quality\n",
        "- We use fairseq's sequence generator for beam search to generate translation hypotheses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "2og80HYQPAKq"
      },
      "outputs": [],
      "source": [
        "# fairseq's beam search generator\n",
        "# given model and input seqeunce, produce translation hypotheses by beam search\n",
        "sequence_generator = task.build_generator([model], config)\n",
        "\n",
        "def decode(toks, dictionary):\n",
        "    # convert from Tensor to human readable sentence\n",
        "    s = dictionary.string(\n",
        "        toks.int().cpu(),\n",
        "        config.post_process,\n",
        "    )\n",
        "    return s if s else \"<unk>\"\n",
        "\n",
        "def inference_step(sample, model):\n",
        "    gen_out = sequence_generator.generate([model], sample)\n",
        "    srcs = []\n",
        "    hyps = []\n",
        "    refs = []\n",
        "    for i in range(len(gen_out)):\n",
        "        # for each sample, collect the input, hypothesis and reference, later be used to calculate BLEU\n",
        "        srcs.append(decode(\n",
        "            utils.strip_pad(sample[\"net_input\"][\"src_tokens\"][i], task.source_dictionary.pad()), \n",
        "            task.source_dictionary,\n",
        "        ))\n",
        "        hyps.append(decode(\n",
        "            gen_out[i][0][\"tokens\"], # 0 indicates using the top hypothesis in beam\n",
        "            task.target_dictionary,\n",
        "        ))\n",
        "        refs.append(decode(\n",
        "            utils.strip_pad(sample[\"target\"][i], task.target_dictionary.pad()), \n",
        "            task.target_dictionary,\n",
        "        ))\n",
        "    return srcs, hyps, refs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "y1o7LeDkPDsd"
      },
      "outputs": [],
      "source": [
        "import shutil\n",
        "import sacrebleu\n",
        "\n",
        "def validate(model, task, criterion, log_to_wandb=True):\n",
        "    logger.info('begin validation')\n",
        "    itr = load_data_iterator(task, \"valid\", 1, config.max_tokens, config.num_workers).next_epoch_itr(shuffle=False)\n",
        "    \n",
        "    stats = {\"loss\":[], \"bleu\": 0, \"srcs\":[], \"hyps\":[], \"refs\":[]}\n",
        "    srcs = []\n",
        "    hyps = []\n",
        "    refs = []\n",
        "    \n",
        "    model.eval()\n",
        "    progress = tqdm.tqdm(itr, desc=f\"validation\", leave=False)\n",
        "    with torch.no_grad():\n",
        "        for i, sample in enumerate(progress):\n",
        "            # validation loss\n",
        "            sample = utils.move_to_cuda(sample, device=device)\n",
        "            net_output = model.forward(**sample[\"net_input\"])\n",
        "\n",
        "            lprobs = F.log_softmax(net_output[0], -1)\n",
        "            target = sample[\"target\"]\n",
        "            sample_size = sample[\"ntokens\"]\n",
        "            loss = criterion(lprobs.view(-1, lprobs.size(-1)), target.view(-1)) / sample_size\n",
        "            progress.set_postfix(valid_loss=loss.item())\n",
        "            stats[\"loss\"].append(loss)\n",
        "            \n",
        "            # do inference\n",
        "            s, h, r = inference_step(sample, model)\n",
        "            srcs.extend(s)\n",
        "            hyps.extend(h)\n",
        "            refs.extend(r)\n",
        "            \n",
        "    tok = 'zh' if task.cfg.target_lang == 'zh' else '13a'\n",
        "    stats[\"loss\"] = torch.stack(stats[\"loss\"]).mean().item()\n",
        "    stats[\"bleu\"] = sacrebleu.corpus_bleu(hyps, [refs], tokenize=tok) # 計算BLEU score\n",
        "    stats[\"srcs\"] = srcs\n",
        "    stats[\"hyps\"] = hyps\n",
        "    stats[\"refs\"] = refs\n",
        "    \n",
        "    if config.use_wandb and log_to_wandb:\n",
        "        wandb.log({\n",
        "            \"valid/loss\": stats[\"loss\"],\n",
        "            \"valid/bleu\": stats[\"bleu\"].score,\n",
        "        }, commit=False)\n",
        "    \n",
        "    showid = np.random.randint(len(hyps))\n",
        "    logger.info(\"example source: \" + srcs[showid])\n",
        "    logger.info(\"example hypothesis: \" + hyps[showid])\n",
        "    logger.info(\"example reference: \" + refs[showid])\n",
        "    \n",
        "    # show bleu results\n",
        "    logger.info(f\"validation loss:\\t{stats['loss']:.4f}\")\n",
        "    logger.info(stats[\"bleu\"].format())\n",
        "    return stats"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1sRF6nd4PGEE"
      },
      "source": [
        "# Save and Load Model Weights\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "edBuLlkuPGr9"
      },
      "outputs": [],
      "source": [
        "def validate_and_save(model, task, criterion, optimizer, epoch, save=True):   \n",
        "    stats = validate(model, task, criterion)\n",
        "    bleu = stats['bleu']\n",
        "    loss = stats['loss']\n",
        "    if save:\n",
        "        # save epoch checkpoints\n",
        "        savedir = Path(config.savedir).absolute()\n",
        "        savedir.mkdir(parents=True, exist_ok=True)\n",
        "        \n",
        "        check = {\n",
        "            \"model\": model.state_dict(),\n",
        "            \"stats\": {\"bleu\": bleu.score, \"loss\": loss},\n",
        "            \"optim\": {\"step\": optimizer._step}\n",
        "        }\n",
        "        torch.save(check, savedir/f\"checkpoint{epoch}.pt\")\n",
        "        shutil.copy(savedir/f\"checkpoint{epoch}.pt\", savedir/f\"checkpoint_last.pt\")\n",
        "        logger.info(f\"saved epoch checkpoint: {savedir}/checkpoint{epoch}.pt\")\n",
        "    \n",
        "        # save epoch samples\n",
        "        with open(savedir/f\"samples{epoch}.{config.source_lang}-{config.target_lang}.txt\", \"w\") as f:\n",
        "            for s, h in zip(stats[\"srcs\"], stats[\"hyps\"]):\n",
        "                f.write(f\"{s}\\t{h}\\n\")\n",
        "\n",
        "        # get best valid bleu    \n",
        "        if getattr(validate_and_save, \"best_bleu\", 0) < bleu.score:\n",
        "            validate_and_save.best_bleu = bleu.score\n",
        "            torch.save(check, savedir/f\"checkpoint_best.pt\")\n",
        "            \n",
        "        del_file = savedir / f\"checkpoint{epoch - config.keep_last_epochs}.pt\"\n",
        "        if del_file.exists():\n",
        "            del_file.unlink()\n",
        "    \n",
        "    return stats\n",
        "\n",
        "def try_load_checkpoint(model, optimizer=None, name=None):\n",
        "    name = name if name else \"checkpoint_last.pt\"\n",
        "    checkpath = Path(config.savedir)/name\n",
        "    if checkpath.exists():\n",
        "        check = torch.load(checkpath)\n",
        "        model.load_state_dict(check[\"model\"])\n",
        "        stats = check[\"stats\"]\n",
        "        step = \"unknown\"\n",
        "        if optimizer != None:\n",
        "            optimizer._step = step = check[\"optim\"][\"step\"]\n",
        "        logger.info(f\"loaded checkpoint {checkpath}: step={step} loss={stats['loss']} bleu={stats['bleu']}\")\n",
        "    else:\n",
        "        logger.info(f\"no checkpoints found at {checkpath}!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KyIFpibfPJ5u"
      },
      "source": [
        "# Main\n",
        "## Training loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "hu7RZbCUPKQr"
      },
      "outputs": [],
      "source": [
        "model = model.to(device=device)\n",
        "criterion = criterion.to(device=device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5xxlJxU2PeAo",
        "outputId": "151dd30f-d0a4-45ef-eb20-058c827dad43"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-04-05 05:32:02 | INFO | hw5.seq2seq | task: TranslationTask\n",
            "2022-04-05 05:32:02 | INFO | hw5.seq2seq | encoder: TransformerEncoder\n",
            "2022-04-05 05:32:02 | INFO | hw5.seq2seq | decoder: TransformerDecoder\n",
            "2022-04-05 05:32:02 | INFO | hw5.seq2seq | criterion: LabelSmoothedCrossEntropyCriterion\n",
            "2022-04-05 05:32:02 | INFO | hw5.seq2seq | optimizer: NoamOpt\n",
            "2022-04-05 05:32:02 | INFO | hw5.seq2seq | num. model params: 52,324,352 (num. trained: 52,324,352)\n",
            "2022-04-05 05:32:02 | INFO | hw5.seq2seq | max tokens per batch = 8192, accumulate steps = 2\n"
          ]
        }
      ],
      "source": [
        "logger.info(\"task: {}\".format(task.__class__.__name__))\n",
        "logger.info(\"encoder: {}\".format(model.encoder.__class__.__name__))\n",
        "logger.info(\"decoder: {}\".format(model.decoder.__class__.__name__))\n",
        "logger.info(\"criterion: {}\".format(criterion.__class__.__name__))\n",
        "logger.info(\"optimizer: {}\".format(optimizer.__class__.__name__))\n",
        "logger.info(\n",
        "    \"num. model params: {:,} (num. trained: {:,})\".format(\n",
        "        sum(p.numel() for p in model.parameters()),\n",
        "        sum(p.numel() for p in model.parameters() if p.requires_grad),\n",
        "    )\n",
        ")\n",
        "logger.info(f\"max tokens per batch = {config.max_tokens}, accumulate steps = {config.accum_steps}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "MSPRqpQUPfaX"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-04-05 05:32:02 | WARNING | fairseq.tasks.fairseq_task | 1 samples have invalid sizes and will be skipped, max_positions=(1024, 1024), first few sample ids=[326738]\n",
            "2022-04-05 05:32:02 | INFO | hw5.seq2seq | no checkpoints found at checkpoints/transformer-bt/checkpoint_last.pt!\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c59bb28c799541fa9fa9b27654f4dfa5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "train epoch 1:   0%|          | 0/800 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-04-05 05:44:19 | INFO | hw5.seq2seq | training loss: 5.6079\n",
            "2022-04-05 05:44:19 | INFO | hw5.seq2seq | begin validation\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "212817a58e71415f9a7720e970e61497",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "validation:   0%|          | 0/27 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/weiweichi/.local/lib/python3.8/site-packages/fairseq/search.py:140: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
            "  beams_buf = indices_buf // vocab_size\n",
            "/home/weiweichi/.local/lib/python3.8/site-packages/fairseq/sequence_generator.py:657: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
            "  unfin_idx = idx // beam_size\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-04-05 05:44:58 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')\n",
            "2022-04-05 05:44:58 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "2022-04-05 05:44:58 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n",
            "2022-04-05 05:44:58 | INFO | hw5.seq2seq | example source: 艾曼達 , 能否請您分享您如何失去手臂的 ?\n",
            "2022-04-05 05:44:58 | INFO | hw5.seq2seq | example hypothesis: johnia , can you can tell you how do you get your hands ?\n",
            "2022-04-05 05:44:58 | INFO | hw5.seq2seq | example reference: so amanda , would you please tell us how you lost your arm ?\n",
            "2022-04-05 05:44:58 | INFO | hw5.seq2seq | validation loss:\t4.2844\n",
            "2022-04-05 05:44:58 | INFO | hw5.seq2seq | BLEU = 3.37 29.9/6.3/1.8/0.5 (BP = 0.910 ratio = 0.914 hyp_len = 69583 ref_len = 76142)\n",
            "2022-04-05 05:44:58 | INFO | hw5.seq2seq | saved epoch checkpoint: /home/weiweichi/weichi/HW5/checkpoints/transformer-bt/checkpoint1.pt\n",
            "2022-04-05 05:44:58 | INFO | hw5.seq2seq | end of epoch 1\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2447cfbca654443fabc4645b0f558a99",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "train epoch 2:   0%|          | 0/800 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-04-05 05:57:15 | INFO | hw5.seq2seq | training loss: 3.8616\n",
            "2022-04-05 05:57:15 | INFO | hw5.seq2seq | begin validation\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1bc28c95755a4a0da9f7767306c7b7d9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "validation:   0%|          | 0/27 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-04-05 05:57:50 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')\n",
            "2022-04-05 05:57:50 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "2022-04-05 05:57:50 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n",
            "2022-04-05 05:57:50 | INFO | hw5.seq2seq | example source: 在未來兩年 , 我的工作是設計一個總體計畫並於十年內執行本計劃-當然 , 這需要眾人攜手合作 。\n",
            "2022-04-05 05:57:50 | INFO | hw5.seq2seq | example hypothesis: in the next two years , my job is to design a sumarian project , and that's a project that's going to work in a decade , of course , that's going to work together .\n",
            "2022-04-05 05:57:50 | INFO | hw5.seq2seq | example reference: that is my job for the next two years , to design an entire master plan , and then for the next 10 years to implement it of course , with so many other people .\n",
            "2022-04-05 05:57:50 | INFO | hw5.seq2seq | validation loss:\t3.4247\n",
            "2022-04-05 05:57:50 | INFO | hw5.seq2seq | BLEU = 9.52 40.0/13.9/6.0/2.7 (BP = 0.980 ratio = 0.980 hyp_len = 74650 ref_len = 76142)\n",
            "2022-04-05 05:57:52 | INFO | hw5.seq2seq | saved epoch checkpoint: /home/weiweichi/weichi/HW5/checkpoints/transformer-bt/checkpoint2.pt\n",
            "2022-04-05 05:57:54 | INFO | hw5.seq2seq | end of epoch 2\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5a2e0fc17f034e788ffa498c703d3c43",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "train epoch 3:   0%|          | 0/800 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-04-05 06:10:08 | INFO | hw5.seq2seq | training loss: 3.2907\n",
            "2022-04-05 06:10:08 | INFO | hw5.seq2seq | begin validation\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "418875cdf34a416f9093ccb89e86f4c8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "validation:   0%|          | 0/27 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-04-05 06:10:38 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')\n",
            "2022-04-05 06:10:38 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "2022-04-05 06:10:38 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n",
            "2022-04-05 06:10:38 | INFO | hw5.seq2seq | example source: 如果我們能夠改變這個動力 , 首先 , 創造人口密度更高更適合居住的城市...\n",
            "2022-04-05 06:10:38 | INFO | hw5.seq2seq | example hypothesis: if we can change this movement , the first density of creating density is better for the city .\n",
            "2022-04-05 06:10:38 | INFO | hw5.seq2seq | example reference: if we can change the dynamic , by first of all creating cities that are denser and more livable . . .\n",
            "2022-04-05 06:10:38 | INFO | hw5.seq2seq | validation loss:\t3.1152\n",
            "2022-04-05 06:10:38 | INFO | hw5.seq2seq | BLEU = 11.67 52.8/21.8/10.6/5.3 (BP = 0.734 ratio = 0.764 hyp_len = 58167 ref_len = 76142)\n",
            "2022-04-05 06:10:40 | INFO | hw5.seq2seq | saved epoch checkpoint: /home/weiweichi/weichi/HW5/checkpoints/transformer-bt/checkpoint3.pt\n",
            "2022-04-05 06:10:42 | INFO | hw5.seq2seq | end of epoch 3\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bbf48b860a464b9cbec0e96dc877b7f2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "train epoch 4:   0%|          | 0/800 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-04-05 06:22:59 | INFO | hw5.seq2seq | training loss: 3.0452\n",
            "2022-04-05 06:22:59 | INFO | hw5.seq2seq | begin validation\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fe1709d6c68942ccb1c4b972c906659a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "validation:   0%|          | 0/27 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-04-05 06:23:31 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')\n",
            "2022-04-05 06:23:31 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "2022-04-05 06:23:31 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n",
            "2022-04-05 06:23:31 | INFO | hw5.seq2seq | example source: 他將與我同行 ,\n",
            "2022-04-05 06:23:31 | INFO | hw5.seq2seq | example hypothesis: he's going to work with me .\n",
            "2022-04-05 06:23:31 | INFO | hw5.seq2seq | example reference: he is coming with me .\n",
            "2022-04-05 06:23:31 | INFO | hw5.seq2seq | validation loss:\t2.9893\n",
            "2022-04-05 06:23:31 | INFO | hw5.seq2seq | BLEU = 14.10 50.6/21.6/10.7/5.5 (BP = 0.885 ratio = 0.891 hyp_len = 67837 ref_len = 76142)\n",
            "2022-04-05 06:23:33 | INFO | hw5.seq2seq | saved epoch checkpoint: /home/weiweichi/weichi/HW5/checkpoints/transformer-bt/checkpoint4.pt\n",
            "2022-04-05 06:23:35 | INFO | hw5.seq2seq | end of epoch 4\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "17873c6a3444460c8da1ddbed0f65026",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "train epoch 5:   0%|          | 0/800 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-04-05 06:35:53 | INFO | hw5.seq2seq | training loss: 2.9167\n",
            "2022-04-05 06:35:53 | INFO | hw5.seq2seq | begin validation\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b671cbd2d9324a7ab0e61439b18ba3ee",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "validation:   0%|          | 0/27 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-04-05 06:36:27 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')\n",
            "2022-04-05 06:36:27 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "2022-04-05 06:36:27 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n",
            "2022-04-05 06:36:27 | INFO | hw5.seq2seq | example source: 這叫快速通關走道或vip票\n",
            "2022-04-05 06:36:27 | INFO | hw5.seq2seq | example hypothesis: it's called a rapid reference or vip .\n",
            "2022-04-05 06:36:27 | INFO | hw5.seq2seq | example reference: they call them fast track or vip tickets .\n",
            "2022-04-05 06:36:27 | INFO | hw5.seq2seq | validation loss:\t2.9207\n",
            "2022-04-05 06:36:27 | INFO | hw5.seq2seq | BLEU = 15.33 49.4/21.5/10.8/5.6 (BP = 0.962 ratio = 0.963 hyp_len = 73317 ref_len = 76142)\n",
            "2022-04-05 06:36:29 | INFO | hw5.seq2seq | saved epoch checkpoint: /home/weiweichi/weichi/HW5/checkpoints/transformer-bt/checkpoint5.pt\n",
            "2022-04-05 06:36:31 | INFO | hw5.seq2seq | end of epoch 5\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "85d7016ab10e45c8bb45ec4b7a18c9ed",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "train epoch 6:   0%|          | 0/800 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-04-05 06:48:48 | INFO | hw5.seq2seq | training loss: 2.8097\n",
            "2022-04-05 06:48:48 | INFO | hw5.seq2seq | begin validation\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cf2b2b14497c473789ec4d1c8d4c8a39",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "validation:   0%|          | 0/27 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-04-05 06:49:20 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')\n",
            "2022-04-05 06:49:20 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "2022-04-05 06:49:20 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n",
            "2022-04-05 06:49:20 | INFO | hw5.seq2seq | example source: 可能我們會想要把它用在某些結構上之類的 。\n",
            "2022-04-05 06:49:20 | INFO | hw5.seq2seq | example hypothesis: maybe we would like to use it for some structures .\n",
            "2022-04-05 06:49:20 | INFO | hw5.seq2seq | example reference: probably we're going to want it for some structures , and so on .\n",
            "2022-04-05 06:49:20 | INFO | hw5.seq2seq | validation loss:\t2.7867\n",
            "2022-04-05 06:49:20 | INFO | hw5.seq2seq | BLEU = 16.51 52.7/24.0/12.6/6.9 (BP = 0.907 ratio = 0.911 hyp_len = 69386 ref_len = 76142)\n",
            "2022-04-05 06:49:22 | INFO | hw5.seq2seq | saved epoch checkpoint: /home/weiweichi/weichi/HW5/checkpoints/transformer-bt/checkpoint6.pt\n",
            "2022-04-05 06:49:24 | INFO | hw5.seq2seq | end of epoch 6\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3f6a080778c540f2b61c9cbfbbcf0d22",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "train epoch 7:   0%|          | 0/800 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-04-05 07:01:40 | INFO | hw5.seq2seq | training loss: 2.6867\n",
            "2022-04-05 07:01:40 | INFO | hw5.seq2seq | begin validation\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9c2672ddc1f3458cb43d4e7428228f2f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "validation:   0%|          | 0/27 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-04-05 07:02:15 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')\n",
            "2022-04-05 07:02:15 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "2022-04-05 07:02:15 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n",
            "2022-04-05 07:02:15 | INFO | hw5.seq2seq | example source: 最後還有支付能力的問題\n",
            "2022-04-05 07:02:15 | INFO | hw5.seq2seq | example hypothesis: and then finally , there's a problem of payment .\n",
            "2022-04-05 07:02:15 | INFO | hw5.seq2seq | example reference: and then there's finally there's the affordability question .\n",
            "2022-04-05 07:02:15 | INFO | hw5.seq2seq | validation loss:\t2.7277\n",
            "2022-04-05 07:02:15 | INFO | hw5.seq2seq | BLEU = 17.33 49.9/22.9/12.0/6.7 (BP = 0.996 ratio = 0.996 hyp_len = 75829 ref_len = 76142)\n",
            "2022-04-05 07:02:17 | INFO | hw5.seq2seq | saved epoch checkpoint: /home/weiweichi/weichi/HW5/checkpoints/transformer-bt/checkpoint7.pt\n",
            "2022-04-05 07:02:19 | INFO | hw5.seq2seq | end of epoch 7\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5a0e647bd5144103baf67fabd2ff8f67",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "train epoch 8:   0%|          | 0/800 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-04-05 07:14:34 | INFO | hw5.seq2seq | training loss: 2.5979\n",
            "2022-04-05 07:14:34 | INFO | hw5.seq2seq | begin validation\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e7355daf5e9747c385746a253cc2f577",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "validation:   0%|          | 0/27 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-04-05 07:15:06 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')\n",
            "2022-04-05 07:15:06 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "2022-04-05 07:15:06 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n",
            "2022-04-05 07:15:06 | INFO | hw5.seq2seq | example source: 這相當於每年從海裡撈出全體中國人的重量 。\n",
            "2022-04-05 07:15:06 | INFO | hw5.seq2seq | example hypothesis: that's the equivalent of the weight of the chinese every year .\n",
            "2022-04-05 07:15:06 | INFO | hw5.seq2seq | example reference: that's the equivalent of the human weight of china taken out of the sea every year .\n",
            "2022-04-05 07:15:06 | INFO | hw5.seq2seq | validation loss:\t2.6677\n",
            "2022-04-05 07:15:06 | INFO | hw5.seq2seq | BLEU = 18.86 54.3/26.1/14.2/8.1 (BP = 0.939 ratio = 0.940 hyp_len = 71606 ref_len = 76142)\n",
            "2022-04-05 07:15:08 | INFO | hw5.seq2seq | saved epoch checkpoint: /home/weiweichi/weichi/HW5/checkpoints/transformer-bt/checkpoint8.pt\n",
            "2022-04-05 07:15:10 | INFO | hw5.seq2seq | end of epoch 8\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0ef121c1f91d48ffb68ef81673970595",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "train epoch 9:   0%|          | 0/800 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-04-05 07:27:27 | INFO | hw5.seq2seq | training loss: 2.5251\n",
            "2022-04-05 07:27:27 | INFO | hw5.seq2seq | begin validation\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9446c146eb194c31999eda06c925ff83",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "validation:   0%|          | 0/27 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-04-05 07:27:57 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')\n",
            "2022-04-05 07:27:57 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "2022-04-05 07:27:57 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n",
            "2022-04-05 07:27:57 | INFO | hw5.seq2seq | example source: 謝謝 。\n",
            "2022-04-05 07:27:57 | INFO | hw5.seq2seq | example hypothesis: thank you .\n",
            "2022-04-05 07:27:57 | INFO | hw5.seq2seq | example reference: thank you .\n",
            "2022-04-05 07:27:57 | INFO | hw5.seq2seq | validation loss:\t2.6663\n",
            "2022-04-05 07:27:57 | INFO | hw5.seq2seq | BLEU = 17.96 57.8/28.1/15.6/9.0 (BP = 0.823 ratio = 0.837 hyp_len = 63699 ref_len = 76142)\n",
            "2022-04-05 07:27:59 | INFO | hw5.seq2seq | saved epoch checkpoint: /home/weiweichi/weichi/HW5/checkpoints/transformer-bt/checkpoint9.pt\n",
            "2022-04-05 07:27:59 | INFO | hw5.seq2seq | end of epoch 9\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8e042d11013747379b767e0bafb31569",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "train epoch 10:   0%|          | 0/800 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-04-05 07:40:14 | INFO | hw5.seq2seq | training loss: 2.4649\n",
            "2022-04-05 07:40:14 | INFO | hw5.seq2seq | begin validation\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f921029629c24d2bb59713b6e1d40853",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "validation:   0%|          | 0/27 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-04-05 07:40:46 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')\n",
            "2022-04-05 07:40:46 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "2022-04-05 07:40:46 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n",
            "2022-04-05 07:40:46 | INFO | hw5.seq2seq | example source: 合作社的成員是自我選拔 。\n",
            "2022-04-05 07:40:46 | INFO | hw5.seq2seq | example hypothesis: cooperational community members are selfconsulation .\n",
            "2022-04-05 07:40:46 | INFO | hw5.seq2seq | example reference: the slime mould collective membership is selfselecting .\n",
            "2022-04-05 07:40:46 | INFO | hw5.seq2seq | validation loss:\t2.6272\n",
            "2022-04-05 07:40:46 | INFO | hw5.seq2seq | BLEU = 19.61 56.3/27.6/15.5/9.1 (BP = 0.907 ratio = 0.911 hyp_len = 69388 ref_len = 76142)\n",
            "2022-04-05 07:40:48 | INFO | hw5.seq2seq | saved epoch checkpoint: /home/weiweichi/weichi/HW5/checkpoints/transformer-bt/checkpoint10.pt\n",
            "2022-04-05 07:40:50 | INFO | hw5.seq2seq | end of epoch 10\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f178a1beb0094204965d84edcfeb4909",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "train epoch 11:   0%|          | 0/800 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-04-05 07:53:03 | INFO | hw5.seq2seq | training loss: 2.4138\n",
            "2022-04-05 07:53:03 | INFO | hw5.seq2seq | begin validation\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bd498da8687142bcb98b461462533f5b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "validation:   0%|          | 0/27 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-04-05 07:53:36 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')\n",
            "2022-04-05 07:53:36 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "2022-04-05 07:53:36 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n",
            "2022-04-05 07:53:36 | INFO | hw5.seq2seq | example source: 我製作了實體版的 「 笨鳥先飛 」 , 而它不會從應用程式商店下架 。\n",
            "2022-04-05 07:53:36 | INFO | hw5.seq2seq | example hypothesis: i made physical versions of stupid birds , and it didn't get off the app store .\n",
            "2022-04-05 07:53:36 | INFO | hw5.seq2seq | example reference: i made a physical version of flappy bird that could never be taken off the app store .\n",
            "2022-04-05 07:53:36 | INFO | hw5.seq2seq | validation loss:\t2.6107\n",
            "2022-04-05 07:53:36 | INFO | hw5.seq2seq | BLEU = 19.79 55.1/26.8/14.9/8.6 (BP = 0.949 ratio = 0.950 hyp_len = 72354 ref_len = 76142)\n",
            "2022-04-05 07:53:38 | INFO | hw5.seq2seq | saved epoch checkpoint: /home/weiweichi/weichi/HW5/checkpoints/transformer-bt/checkpoint11.pt\n",
            "2022-04-05 07:53:40 | INFO | hw5.seq2seq | end of epoch 11\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d9ee41982f6845f1a956adadf6868383",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "train epoch 12:   0%|          | 0/800 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-04-05 08:05:54 | INFO | hw5.seq2seq | training loss: 2.3691\n",
            "2022-04-05 08:05:54 | INFO | hw5.seq2seq | begin validation\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c6e8569e6b2b4ec5b7732e57a6271a59",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "validation:   0%|          | 0/27 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-04-05 08:06:26 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')\n",
            "2022-04-05 08:06:26 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "2022-04-05 08:06:26 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n",
            "2022-04-05 08:06:26 | INFO | hw5.seq2seq | example source: 那樣的特質導致一種網路架構 , 這種架構前所未有 , 其後的其它數位網路也無法比擬 。\n",
            "2022-04-05 08:06:26 | INFO | hw5.seq2seq | example hypothesis: that trait leads to a framework that has never been possible before , and the rest of the digital networks aren't even more likely to compare .\n",
            "2022-04-05 08:06:26 | INFO | hw5.seq2seq | example reference: that ethos led to a network architecture , a structure that was unlike other digital networks then or since .\n",
            "2022-04-05 08:06:26 | INFO | hw5.seq2seq | validation loss:\t2.6080\n",
            "2022-04-05 08:06:26 | INFO | hw5.seq2seq | BLEU = 20.10 55.9/27.6/15.5/9.1 (BP = 0.930 ratio = 0.933 hyp_len = 71011 ref_len = 76142)\n",
            "2022-04-05 08:06:28 | INFO | hw5.seq2seq | saved epoch checkpoint: /home/weiweichi/weichi/HW5/checkpoints/transformer-bt/checkpoint12.pt\n",
            "2022-04-05 08:06:30 | INFO | hw5.seq2seq | end of epoch 12\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0618b93ad6d3476d9eee1789611cb393",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "train epoch 13:   0%|          | 0/800 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-04-05 08:18:45 | INFO | hw5.seq2seq | training loss: 2.3292\n",
            "2022-04-05 08:18:45 | INFO | hw5.seq2seq | begin validation\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cb458a65cd364f93b2a85c52ee3cd828",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "validation:   0%|          | 0/27 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-04-05 08:19:18 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')\n",
            "2022-04-05 08:19:18 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "2022-04-05 08:19:18 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n",
            "2022-04-05 08:19:18 | INFO | hw5.seq2seq | example source: 我是個運動員 。 那是我唯一懂得的事 , 也是唯一做過的事 。\n",
            "2022-04-05 08:19:18 | INFO | hw5.seq2seq | example hypothesis: i'm an athlete . that's the only thing i knew , and that's the only thing i ever did .\n",
            "2022-04-05 08:19:18 | INFO | hw5.seq2seq | example reference: i was an athlete . that's all i knew . that's all i'd done .\n",
            "2022-04-05 08:19:18 | INFO | hw5.seq2seq | validation loss:\t2.5987\n",
            "2022-04-05 08:19:18 | INFO | hw5.seq2seq | BLEU = 20.21 56.2/27.8/15.6/9.2 (BP = 0.930 ratio = 0.932 hyp_len = 70986 ref_len = 76142)\n",
            "2022-04-05 08:19:20 | INFO | hw5.seq2seq | saved epoch checkpoint: /home/weiweichi/weichi/HW5/checkpoints/transformer-bt/checkpoint13.pt\n",
            "2022-04-05 08:19:22 | INFO | hw5.seq2seq | end of epoch 13\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "55b903dd72ed4d438382be8f10ccc1c8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "train epoch 14:   0%|          | 0/800 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-04-05 08:31:39 | INFO | hw5.seq2seq | training loss: 2.2930\n",
            "2022-04-05 08:31:39 | INFO | hw5.seq2seq | begin validation\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7a2e236bfe9744f9ae40fe5e9c66e32f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "validation:   0%|          | 0/27 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-04-05 08:32:11 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')\n",
            "2022-04-05 08:32:11 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "2022-04-05 08:32:11 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n",
            "2022-04-05 08:32:11 | INFO | hw5.seq2seq | example source: 我可以想像一個未來 , 在這個未來中 , 我們會很高興看到學齡前兒童與螢幕互動 。\n",
            "2022-04-05 08:32:11 | INFO | hw5.seq2seq | example hypothesis: i could imagine a future where we would be happy to see preschoolers interacting with screens in the future .\n",
            "2022-04-05 08:32:11 | INFO | hw5.seq2seq | example reference: i can envision a future where we would be excited to see a preschooler interacting with a screen .\n",
            "2022-04-05 08:32:11 | INFO | hw5.seq2seq | validation loss:\t2.6085\n",
            "2022-04-05 08:32:11 | INFO | hw5.seq2seq | BLEU = 20.19 56.4/27.9/15.7/9.2 (BP = 0.925 ratio = 0.927 hyp_len = 70613 ref_len = 76142)\n",
            "2022-04-05 08:32:13 | INFO | hw5.seq2seq | saved epoch checkpoint: /home/weiweichi/weichi/HW5/checkpoints/transformer-bt/checkpoint14.pt\n",
            "2022-04-05 08:32:13 | INFO | hw5.seq2seq | end of epoch 14\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9ca25895af1b42d7b296ec531bf81d91",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "train epoch 15:   0%|          | 0/800 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-04-05 08:44:31 | INFO | hw5.seq2seq | training loss: 2.2615\n",
            "2022-04-05 08:44:31 | INFO | hw5.seq2seq | begin validation\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b030cf55de5c4f02a8ed4895d9a4fcc7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "validation:   0%|          | 0/27 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-04-05 08:45:03 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')\n",
            "2022-04-05 08:45:03 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "2022-04-05 08:45:03 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n",
            "2022-04-05 08:45:03 | INFO | hw5.seq2seq | example source: 裡面沒有鋪設好的道路 , 也沒有水泥的停車位地基 。 在拖車停車位之間也沒有圍籬 。\n",
            "2022-04-05 08:45:03 | INFO | hw5.seq2seq | example hypothesis: there are no roads in there , no cement status , no fence between the trailer parking spaces .\n",
            "2022-04-05 08:45:03 | INFO | hw5.seq2seq | example reference: it didn't have any paved roads in it , it didn't have the concrete slabs , it didn't have fencing to portion off your trailer slot from other trailer slots .\n",
            "2022-04-05 08:45:03 | INFO | hw5.seq2seq | validation loss:\t2.6016\n",
            "2022-04-05 08:45:03 | INFO | hw5.seq2seq | BLEU = 20.18 56.1/27.8/15.7/9.3 (BP = 0.925 ratio = 0.927 hyp_len = 70600 ref_len = 76142)\n",
            "2022-04-05 08:45:05 | INFO | hw5.seq2seq | saved epoch checkpoint: /home/weiweichi/weichi/HW5/checkpoints/transformer-bt/checkpoint15.pt\n",
            "2022-04-05 08:45:05 | INFO | hw5.seq2seq | end of epoch 15\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7301cc00de2e405395a70c783cabc198",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "train epoch 16:   0%|          | 0/800 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-04-05 08:57:21 | INFO | hw5.seq2seq | training loss: 2.2308\n",
            "2022-04-05 08:57:21 | INFO | hw5.seq2seq | begin validation\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2d25bc5b22a64adca407fcdfdd4be46d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "validation:   0%|          | 0/27 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-04-05 08:57:54 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')\n",
            "2022-04-05 08:57:54 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "2022-04-05 08:57:54 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n",
            "2022-04-05 08:57:54 | INFO | hw5.seq2seq | example source: 嬰兒不會説話 , 對吧 ? 」\n",
            "2022-04-05 08:57:54 | INFO | hw5.seq2seq | example hypothesis: babies don't talk , right ? \"\n",
            "2022-04-05 08:57:54 | INFO | hw5.seq2seq | example reference: infants can't talk , right ? \"\n",
            "2022-04-05 08:57:54 | INFO | hw5.seq2seq | validation loss:\t2.6035\n",
            "2022-04-05 08:57:54 | INFO | hw5.seq2seq | BLEU = 20.14 56.2/27.8/15.6/9.1 (BP = 0.928 ratio = 0.930 hyp_len = 70818 ref_len = 76142)\n",
            "2022-04-05 08:57:56 | INFO | hw5.seq2seq | saved epoch checkpoint: /home/weiweichi/weichi/HW5/checkpoints/transformer-bt/checkpoint16.pt\n",
            "2022-04-05 08:57:56 | INFO | hw5.seq2seq | end of epoch 16\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "84e2f2bdb3d941248cab8007e6f1c0a1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "train epoch 17:   0%|          | 0/800 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-04-05 09:10:12 | INFO | hw5.seq2seq | training loss: 2.2027\n",
            "2022-04-05 09:10:12 | INFO | hw5.seq2seq | begin validation\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d7f3f992c2cb4152b64747310b1ec528",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "validation:   0%|          | 0/27 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-04-05 09:10:46 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')\n",
            "2022-04-05 09:10:46 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "2022-04-05 09:10:46 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n",
            "2022-04-05 09:10:46 | INFO | hw5.seq2seq | example source: 而身為老師、妻子這自然也是我每天都面對的問題\n",
            "2022-04-05 09:10:46 | INFO | hw5.seq2seq | example hypothesis: and as a teacher , as a wife , it's a natural problem for me every day .\n",
            "2022-04-05 09:10:46 | INFO | hw5.seq2seq | example reference: so as a teacher and as a spouse , this is , of course , a problem i confront every day .\n",
            "2022-04-05 09:10:46 | INFO | hw5.seq2seq | validation loss:\t2.6128\n",
            "2022-04-05 09:10:46 | INFO | hw5.seq2seq | BLEU = 20.42 55.0/27.2/15.4/9.0 (BP = 0.957 ratio = 0.957 hyp_len = 72902 ref_len = 76142)\n",
            "2022-04-05 09:10:48 | INFO | hw5.seq2seq | saved epoch checkpoint: /home/weiweichi/weichi/HW5/checkpoints/transformer-bt/checkpoint17.pt\n",
            "2022-04-05 09:10:49 | INFO | hw5.seq2seq | end of epoch 17\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5f819e1ca3b04ac08c949298870c2e5a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "train epoch 18:   0%|          | 0/800 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-04-05 09:23:04 | INFO | hw5.seq2seq | training loss: 2.1784\n",
            "2022-04-05 09:23:04 | INFO | hw5.seq2seq | begin validation\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "29aeea47e1534208ad0e57d08ebc1736",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "validation:   0%|          | 0/27 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-04-05 09:23:36 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')\n",
            "2022-04-05 09:23:36 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "2022-04-05 09:23:36 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n",
            "2022-04-05 09:23:36 | INFO | hw5.seq2seq | example source: 後來我們真的這樣做了 , 那是好事 。\n",
            "2022-04-05 09:23:36 | INFO | hw5.seq2seq | example hypothesis: and we actually did that , and that's a good thing .\n",
            "2022-04-05 09:23:36 | INFO | hw5.seq2seq | example reference: so we did that . it was a good thing .\n",
            "2022-04-05 09:23:36 | INFO | hw5.seq2seq | validation loss:\t2.6152\n",
            "2022-04-05 09:23:36 | INFO | hw5.seq2seq | BLEU = 20.08 55.9/27.5/15.6/9.2 (BP = 0.929 ratio = 0.931 hyp_len = 70892 ref_len = 76142)\n",
            "2022-04-05 09:23:38 | INFO | hw5.seq2seq | saved epoch checkpoint: /home/weiweichi/weichi/HW5/checkpoints/transformer-bt/checkpoint18.pt\n",
            "2022-04-05 09:23:39 | INFO | hw5.seq2seq | end of epoch 18\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9e17427f11084e0ba9d6507a62fbdf5c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "train epoch 19:   0%|          | 0/800 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-04-05 09:35:56 | INFO | hw5.seq2seq | training loss: 2.1555\n",
            "2022-04-05 09:35:56 | INFO | hw5.seq2seq | begin validation\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "74ef24d077ab4ae987543392ca56a516",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "validation:   0%|          | 0/27 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-04-05 09:36:28 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')\n",
            "2022-04-05 09:36:28 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "2022-04-05 09:36:28 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n",
            "2022-04-05 09:36:28 | INFO | hw5.seq2seq | example source: 他們選擇昂貴的檢測他們選擇為體弱的老人動手術\n",
            "2022-04-05 09:36:28 | INFO | hw5.seq2seq | example hypothesis: they chose expensive tests , and they chose surgery for the weak elderly .\n",
            "2022-04-05 09:36:28 | INFO | hw5.seq2seq | example reference: you choose an expensive lab test , you choose to operate on an old and frail patient .\n",
            "2022-04-05 09:36:28 | INFO | hw5.seq2seq | validation loss:\t2.6194\n",
            "2022-04-05 09:36:28 | INFO | hw5.seq2seq | BLEU = 20.60 55.5/27.6/15.6/9.2 (BP = 0.952 ratio = 0.953 hyp_len = 72573 ref_len = 76142)\n",
            "2022-04-05 09:36:30 | INFO | hw5.seq2seq | saved epoch checkpoint: /home/weiweichi/weichi/HW5/checkpoints/transformer-bt/checkpoint19.pt\n",
            "2022-04-05 09:36:32 | INFO | hw5.seq2seq | end of epoch 19\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "04fdae3665034afa901304311ec96e80",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "train epoch 20:   0%|          | 0/800 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-04-05 09:48:48 | INFO | hw5.seq2seq | training loss: 2.1331\n",
            "2022-04-05 09:48:48 | INFO | hw5.seq2seq | begin validation\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6e4bb9cc857e45aaab4d65e403a54624",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "validation:   0%|          | 0/27 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-04-05 09:49:21 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')\n",
            "2022-04-05 09:49:21 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "2022-04-05 09:49:21 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n",
            "2022-04-05 09:49:21 | INFO | hw5.seq2seq | example source: 我是說 , 這些事都在他眼下發生\n",
            "2022-04-05 09:49:21 | INFO | hw5.seq2seq | example hypothesis: i mean , it's all happening under his eyes .\n",
            "2022-04-05 09:49:21 | INFO | hw5.seq2seq | example reference: i mean after all , this whole business happened on his watch .\n",
            "2022-04-05 09:49:21 | INFO | hw5.seq2seq | validation loss:\t2.6316\n",
            "2022-04-05 09:49:21 | INFO | hw5.seq2seq | BLEU = 19.87 55.9/27.4/15.3/9.0 (BP = 0.927 ratio = 0.929 hyp_len = 70761 ref_len = 76142)\n",
            "2022-04-05 09:49:23 | INFO | hw5.seq2seq | saved epoch checkpoint: /home/weiweichi/weichi/HW5/checkpoints/transformer-bt/checkpoint20.pt\n",
            "2022-04-05 09:49:23 | INFO | hw5.seq2seq | end of epoch 20\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f34a7649080249c1a98de3bb272df577",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "train epoch 21:   0%|          | 0/800 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-04-05 10:01:40 | INFO | hw5.seq2seq | training loss: 2.1126\n",
            "2022-04-05 10:01:40 | INFO | hw5.seq2seq | begin validation\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "78005641cfd54a79afa3a9b71e67a799",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "validation:   0%|          | 0/27 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-04-05 10:02:12 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')\n",
            "2022-04-05 10:02:12 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "2022-04-05 10:02:12 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n",
            "2022-04-05 10:02:12 | INFO | hw5.seq2seq | example source: 有50%的車禍發生在十字路口\n",
            "2022-04-05 10:02:12 | INFO | hw5.seq2seq | example hypothesis: fifty percent of crashes happened at crossroads .\n",
            "2022-04-05 10:02:12 | INFO | hw5.seq2seq | example reference: fifty percent of crashes happen at intersections .\n",
            "2022-04-05 10:02:12 | INFO | hw5.seq2seq | validation loss:\t2.6387\n",
            "2022-04-05 10:02:12 | INFO | hw5.seq2seq | BLEU = 20.13 55.9/27.6/15.6/9.1 (BP = 0.930 ratio = 0.932 hyp_len = 70984 ref_len = 76142)\n",
            "2022-04-05 10:02:14 | INFO | hw5.seq2seq | saved epoch checkpoint: /home/weiweichi/weichi/HW5/checkpoints/transformer-bt/checkpoint21.pt\n",
            "2022-04-05 10:02:14 | INFO | hw5.seq2seq | end of epoch 21\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9564a3050c1a48ae9d57291eee9fcdc4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "train epoch 22:   0%|          | 0/800 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-04-05 10:14:29 | INFO | hw5.seq2seq | training loss: 2.0929\n",
            "2022-04-05 10:14:29 | INFO | hw5.seq2seq | begin validation\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8e4e577b3fe643508ac44e9a200dd030",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "validation:   0%|          | 0/27 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-04-05 10:15:00 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')\n",
            "2022-04-05 10:15:00 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "2022-04-05 10:15:00 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n",
            "2022-04-05 10:15:00 | INFO | hw5.seq2seq | example source: 我們要問自己這些問題 , 不論這是多麼的令人不快 。\n",
            "2022-04-05 10:15:00 | INFO | hw5.seq2seq | example hypothesis: we need to ask ourselves these questions , no matter how uncomfortable they are .\n",
            "2022-04-05 10:15:00 | INFO | hw5.seq2seq | example reference: we have to ask ourselves these questions , however unpalatable .\n",
            "2022-04-05 10:15:00 | INFO | hw5.seq2seq | validation loss:\t2.6468\n",
            "2022-04-05 10:15:00 | INFO | hw5.seq2seq | BLEU = 19.82 56.3/27.8/15.6/9.1 (BP = 0.913 ratio = 0.916 hyp_len = 69777 ref_len = 76142)\n",
            "2022-04-05 10:15:03 | INFO | hw5.seq2seq | saved epoch checkpoint: /home/weiweichi/weichi/HW5/checkpoints/transformer-bt/checkpoint22.pt\n",
            "2022-04-05 10:15:03 | INFO | hw5.seq2seq | end of epoch 22\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6939c0965bc944e99bff0e88c3168785",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "train epoch 23:   0%|          | 0/800 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-04-05 10:27:19 | INFO | hw5.seq2seq | training loss: 2.0746\n",
            "2022-04-05 10:27:19 | INFO | hw5.seq2seq | begin validation\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "acc0fa3392cb41c28f6d361a34b5a5a5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "validation:   0%|          | 0/27 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-04-05 10:27:51 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')\n",
            "2022-04-05 10:27:51 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "2022-04-05 10:27:51 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n",
            "2022-04-05 10:27:51 | INFO | hw5.seq2seq | example source: 有些會太靠近恆星 , 會被烤熟 , 有些則太遙遠 , 會被冰凍 。\n",
            "2022-04-05 10:27:51 | INFO | hw5.seq2seq | example hypothesis: some get too close to a star , they get ripped , others get so far away , they get frozen .\n",
            "2022-04-05 10:27:51 | INFO | hw5.seq2seq | example reference: some will be too close to a star and they'll fry , some will be too far away and they'll freeze .\n",
            "2022-04-05 10:27:51 | INFO | hw5.seq2seq | validation loss:\t2.6610\n",
            "2022-04-05 10:27:51 | INFO | hw5.seq2seq | BLEU = 20.28 56.0/27.7/15.7/9.2 (BP = 0.933 ratio = 0.935 hyp_len = 71172 ref_len = 76142)\n",
            "2022-04-05 10:27:53 | INFO | hw5.seq2seq | saved epoch checkpoint: /home/weiweichi/weichi/HW5/checkpoints/transformer-bt/checkpoint23.pt\n",
            "2022-04-05 10:27:53 | INFO | hw5.seq2seq | end of epoch 23\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "daabf446787c4b12976fde78b9b4ed29",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "train epoch 24:   0%|          | 0/800 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-04-05 10:40:09 | INFO | hw5.seq2seq | training loss: 2.0584\n",
            "2022-04-05 10:40:09 | INFO | hw5.seq2seq | begin validation\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1cf88d611b3f4ad79b6cdeb148fa735b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "validation:   0%|          | 0/27 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-04-05 10:40:42 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')\n",
            "2022-04-05 10:40:42 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "2022-04-05 10:40:42 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n",
            "2022-04-05 10:40:42 | INFO | hw5.seq2seq | example source: 我認為大多數的人都不想死但我認為大多數的人都想要控制自己的死亡過程\n",
            "2022-04-05 10:40:42 | INFO | hw5.seq2seq | example hypothesis: i think most people don't want to die , but i think most people want to control their own mortality .\n",
            "2022-04-05 10:40:42 | INFO | hw5.seq2seq | example reference: i think most people don't want to be dead , but i do think most people want to have some control over how their dying process proceeds .\n",
            "2022-04-05 10:40:42 | INFO | hw5.seq2seq | validation loss:\t2.6650\n",
            "2022-04-05 10:40:42 | INFO | hw5.seq2seq | BLEU = 19.95 56.1/27.7/15.5/9.0 (BP = 0.926 ratio = 0.928 hyp_len = 70675 ref_len = 76142)\n",
            "2022-04-05 10:40:44 | INFO | hw5.seq2seq | saved epoch checkpoint: /home/weiweichi/weichi/HW5/checkpoints/transformer-bt/checkpoint24.pt\n",
            "2022-04-05 10:40:44 | INFO | hw5.seq2seq | end of epoch 24\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "aab99af0bcde4f16b2ba13024e2b8572",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "train epoch 25:   0%|          | 0/800 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-04-05 10:53:00 | INFO | hw5.seq2seq | training loss: 2.0421\n",
            "2022-04-05 10:53:00 | INFO | hw5.seq2seq | begin validation\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a7d4c717808c45e9b9fc13de3481f7a9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "validation:   0%|          | 0/27 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-04-05 10:53:32 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')\n",
            "2022-04-05 10:53:32 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "2022-04-05 10:53:32 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n",
            "2022-04-05 10:53:32 | INFO | hw5.seq2seq | example source: 目前我們正在土耳其建造一座更長一點的橋 , 我們也設計了義大利的墨西拿海峽大橋 , 正在等待開始動工的日子 , 天知道是何時 。\n",
            "2022-04-05 10:53:32 | INFO | hw5.seq2seq | example hypothesis: right now , we're building a much longer bridge in turkey , and we're also designing mexican navy bridges that are waiting for the day to start work , and god knows when .\n",
            "2022-04-05 10:53:32 | INFO | hw5.seq2seq | example reference: we're currently working on one in turkey which is a bit longer , and we've designed the messina bridge in italy , which is just waiting to get started with construction one day , who knows when .\n",
            "2022-04-05 10:53:32 | INFO | hw5.seq2seq | validation loss:\t2.6705\n",
            "2022-04-05 10:53:32 | INFO | hw5.seq2seq | BLEU = 20.13 56.4/27.9/15.7/9.3 (BP = 0.919 ratio = 0.922 hyp_len = 70239 ref_len = 76142)\n",
            "2022-04-05 10:53:34 | INFO | hw5.seq2seq | saved epoch checkpoint: /home/weiweichi/weichi/HW5/checkpoints/transformer-bt/checkpoint25.pt\n",
            "2022-04-05 10:53:34 | INFO | hw5.seq2seq | end of epoch 25\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5e93e3145bb541f4983916a8b6bbbff5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "train epoch 26:   0%|          | 0/800 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-04-05 11:05:52 | INFO | hw5.seq2seq | training loss: 2.0269\n",
            "2022-04-05 11:05:52 | INFO | hw5.seq2seq | begin validation\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "07664f4d1061408aaafb1faae25b9da3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "validation:   0%|          | 0/27 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-04-05 11:06:25 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')\n",
            "2022-04-05 11:06:25 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "2022-04-05 11:06:25 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n",
            "2022-04-05 11:06:25 | INFO | hw5.seq2seq | example source: 國王在如雷掌聲中接過皇冠、權仗亨利·克里斯托夫登上離地20米的寶座\n",
            "2022-04-05 11:06:25 | INFO | hw5.seq2seq | example hypothesis: the king had received crowns and authorities in thunder's applause , henry christopher had climbed up 20 meters away from the ground .\n",
            "2022-04-05 11:06:25 | INFO | hw5.seq2seq | example reference: after receiving his ornate crown and scepter , henry christophe ascended his throne , towering 20 meters in the air .\n",
            "2022-04-05 11:06:25 | INFO | hw5.seq2seq | validation loss:\t2.6820\n",
            "2022-04-05 11:06:25 | INFO | hw5.seq2seq | BLEU = 19.76 56.0/27.4/15.2/8.9 (BP = 0.926 ratio = 0.929 hyp_len = 70708 ref_len = 76142)\n",
            "2022-04-05 11:06:27 | INFO | hw5.seq2seq | saved epoch checkpoint: /home/weiweichi/weichi/HW5/checkpoints/transformer-bt/checkpoint26.pt\n",
            "2022-04-05 11:06:27 | INFO | hw5.seq2seq | end of epoch 26\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "22229ca637614a5d8f6fd34da2506a27",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "train epoch 27:   0%|          | 0/800 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-04-05 11:18:43 | INFO | hw5.seq2seq | training loss: 2.0111\n",
            "2022-04-05 11:18:43 | INFO | hw5.seq2seq | begin validation\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1bc11434eedd432482f61b5a5bac424d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "validation:   0%|          | 0/27 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-04-05 11:19:15 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')\n",
            "2022-04-05 11:19:15 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "2022-04-05 11:19:15 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n",
            "2022-04-05 11:19:15 | INFO | hw5.seq2seq | example source: 他們不知道那有多荒謬 , 而我知道 。\n",
            "2022-04-05 11:19:15 | INFO | hw5.seq2seq | example hypothesis: they didn't know how ridiculous that was , and i knew .\n",
            "2022-04-05 11:19:15 | INFO | hw5.seq2seq | example reference: now , they don't know how ridiculous that is , but i do .\n",
            "2022-04-05 11:19:15 | INFO | hw5.seq2seq | validation loss:\t2.6998\n",
            "2022-04-05 11:19:15 | INFO | hw5.seq2seq | BLEU = 20.01 56.2/27.7/15.6/9.1 (BP = 0.924 ratio = 0.926 hyp_len = 70544 ref_len = 76142)\n",
            "2022-04-05 11:19:17 | INFO | hw5.seq2seq | saved epoch checkpoint: /home/weiweichi/weichi/HW5/checkpoints/transformer-bt/checkpoint27.pt\n",
            "2022-04-05 11:19:17 | INFO | hw5.seq2seq | end of epoch 27\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f6e411f2f158405e9cad4b7b4c9b5f57",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "train epoch 28:   0%|          | 0/800 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-04-05 11:31:33 | INFO | hw5.seq2seq | training loss: 1.9982\n",
            "2022-04-05 11:31:33 | INFO | hw5.seq2seq | begin validation\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f1d06c3d7a85488fab57c0a31a475f1c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "validation:   0%|          | 0/27 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-04-05 11:32:06 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')\n",
            "2022-04-05 11:32:06 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "2022-04-05 11:32:06 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n",
            "2022-04-05 11:32:06 | INFO | hw5.seq2seq | example source: 這概念就是大家所知的 「 熱輻射 」 。\n",
            "2022-04-05 11:32:06 | INFO | hw5.seq2seq | example hypothesis: this is the idea that we know about thermal radiation .\n",
            "2022-04-05 11:32:06 | INFO | hw5.seq2seq | example reference: this is a concept known as thermal radiation .\n",
            "2022-04-05 11:32:06 | INFO | hw5.seq2seq | validation loss:\t2.6944\n",
            "2022-04-05 11:32:06 | INFO | hw5.seq2seq | BLEU = 19.94 55.4/27.1/15.2/8.9 (BP = 0.939 ratio = 0.940 hyp_len = 71598 ref_len = 76142)\n",
            "2022-04-05 11:32:08 | INFO | hw5.seq2seq | saved epoch checkpoint: /home/weiweichi/weichi/HW5/checkpoints/transformer-bt/checkpoint28.pt\n",
            "2022-04-05 11:32:08 | INFO | hw5.seq2seq | end of epoch 28\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c2faba6c197045e98c59f05f0ba51f4f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "train epoch 29:   0%|          | 0/800 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-04-05 11:44:24 | INFO | hw5.seq2seq | training loss: 1.9845\n",
            "2022-04-05 11:44:24 | INFO | hw5.seq2seq | begin validation\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0d250f44154f41c686da7a8c0fcd686d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "validation:   0%|          | 0/27 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-04-05 11:44:56 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')\n",
            "2022-04-05 11:44:56 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "2022-04-05 11:44:56 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n",
            "2022-04-05 11:44:56 | INFO | hw5.seq2seq | example source: 老實說 , 我們其實可以提前完成這個企畫 , 但我想我們因為這些喝茶休憩時間多做了三周 。\n",
            "2022-04-05 11:44:56 | INFO | hw5.seq2seq | example hypothesis: and honestly , we can actually finish this project ahead of time , but i think we've done more than three weeks for tea .\n",
            "2022-04-05 11:44:56 | INFO | hw5.seq2seq | example reference: and to be honest with you , we could have finished earlier , but i think it took us three weeks because of all those tea breaks .\n",
            "2022-04-05 11:44:56 | INFO | hw5.seq2seq | validation loss:\t2.7088\n",
            "2022-04-05 11:44:56 | INFO | hw5.seq2seq | BLEU = 19.71 55.9/27.3/15.3/9.0 (BP = 0.920 ratio = 0.923 hyp_len = 70291 ref_len = 76142)\n",
            "2022-04-05 11:44:58 | INFO | hw5.seq2seq | saved epoch checkpoint: /home/weiweichi/weichi/HW5/checkpoints/transformer-bt/checkpoint29.pt\n",
            "2022-04-05 11:44:58 | INFO | hw5.seq2seq | end of epoch 29\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5e1bcae592f74671a22d795875194115",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "train epoch 30:   0%|          | 0/800 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-04-05 11:57:16 | INFO | hw5.seq2seq | training loss: 1.9727\n",
            "2022-04-05 11:57:16 | INFO | hw5.seq2seq | begin validation\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d3fd2006fa344b5fb0b72f6b78d49aef",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "validation:   0%|          | 0/27 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-04-05 11:57:48 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')\n",
            "2022-04-05 11:57:48 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "2022-04-05 11:57:48 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n",
            "2022-04-05 11:57:48 | INFO | hw5.seq2seq | example source: 所以這是個好消息\n",
            "2022-04-05 11:57:48 | INFO | hw5.seq2seq | example hypothesis: so that's the good news .\n",
            "2022-04-05 11:57:48 | INFO | hw5.seq2seq | example reference: so that was good news .\n",
            "2022-04-05 11:57:48 | INFO | hw5.seq2seq | validation loss:\t2.7192\n",
            "2022-04-05 11:57:48 | INFO | hw5.seq2seq | BLEU = 19.79 55.7/27.1/15.2/8.9 (BP = 0.931 ratio = 0.933 hyp_len = 71074 ref_len = 76142)\n",
            "2022-04-05 11:57:50 | INFO | hw5.seq2seq | saved epoch checkpoint: /home/weiweichi/weichi/HW5/checkpoints/transformer-bt/checkpoint30.pt\n",
            "2022-04-05 11:57:50 | INFO | hw5.seq2seq | end of epoch 30\n"
          ]
        }
      ],
      "source": [
        "epoch_itr = load_data_iterator(task, \"train\", config.start_epoch, config.max_tokens, config.num_workers)\n",
        "try_load_checkpoint(model, optimizer, name=config.resume)\n",
        "while epoch_itr.next_epoch_idx <= config.max_epoch:\n",
        "    # train for one epoch\n",
        "    train_one_epoch(epoch_itr, model, task, criterion, optimizer, config.accum_steps)\n",
        "    stats = validate_and_save(model, task, criterion, optimizer, epoch=epoch_itr.epoch)\n",
        "    logger.info(\"end of epoch {}\".format(epoch_itr.epoch))    \n",
        "    epoch_itr = load_data_iterator(task, \"train\", epoch_itr.next_epoch_idx, config.max_tokens, config.num_workers)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KyjRwllxPjtf"
      },
      "source": [
        "# Submission"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "N70Gc6smPi1d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Namespace(checkpoint_upper_bound=None, inputs=['./checkpoints/transformer-bt'], num_epoch_checkpoints=5, num_update_checkpoints=None, output='./checkpoints/transformer-bt/avg_last_5_checkpoint.pt')\n",
            "averaging checkpoints:  ['./checkpoints/transformer-bt/checkpoint30.pt', './checkpoints/transformer-bt/checkpoint29.pt', './checkpoints/transformer-bt/checkpoint28.pt', './checkpoints/transformer-bt/checkpoint27.pt', './checkpoints/transformer-bt/checkpoint26.pt']\n",
            "Finished writing averaged checkpoint to ./checkpoints/transformer-bt/avg_last_5_checkpoint.pt\n"
          ]
        }
      ],
      "source": [
        "# averaging a few checkpoints can have a similar effect to ensemble\n",
        "checkdir=config.savedir\n",
        "!python3 ./fairseq/scripts/average_checkpoints.py \\\n",
        "--inputs {checkdir} \\\n",
        "--num-epoch-checkpoints 5 \\\n",
        "--output {checkdir}/avg_last_5_checkpoint.pt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BAGMiun8PnZy"
      },
      "source": [
        "## Confirm model weights used to generate submission"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "tvRdivVUPnsU"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-04-05 11:57:53 | INFO | hw5.seq2seq | loaded checkpoint checkpoints/transformer-bt/avg_last_5_checkpoint.pt: step=unknown loss=2.719242811203003 bleu=19.786939734245298\n",
            "2022-04-05 11:57:53 | INFO | hw5.seq2seq | begin validation\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4a9f068a15f44c938257bf5f614e81fc",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "validation:   0%|          | 0/27 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-04-05 11:58:25 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')\n",
            "2022-04-05 11:58:25 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "2022-04-05 11:58:25 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n",
            "2022-04-05 11:58:25 | INFO | hw5.seq2seq | example source: 飛蚊可能不太明顯通常是如此\n",
            "2022-04-05 11:58:25 | INFO | hw5.seq2seq | example hypothesis: now , floaters may not be obvious , usually .\n",
            "2022-04-05 11:58:25 | INFO | hw5.seq2seq | example reference: floaters may be only barely distinguishable most of the time .\n",
            "2022-04-05 11:58:25 | INFO | hw5.seq2seq | validation loss:\t2.6695\n",
            "2022-04-05 11:58:25 | INFO | hw5.seq2seq | BLEU = 20.47 56.6/28.1/15.9/9.4 (BP = 0.927 ratio = 0.929 hyp_len = 70750 ref_len = 76142)\n"
          ]
        }
      ],
      "source": [
        "# checkpoint_last.pt : latest epoch\n",
        "# checkpoint_best.pt : highest validation bleu\n",
        "# avg_last_5_checkpoint.pt:　the average of last 5 epochs\n",
        "try_load_checkpoint(model, name=\"avg_last_5_checkpoint.pt\")\n",
        "validate(model, task, criterion, log_to_wandb=False)\n",
        "None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ioAIflXpPsxt"
      },
      "source": [
        "## Generate Prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "oYMxA8FlPtIq"
      },
      "outputs": [],
      "source": [
        "def generate_prediction(model, task, split=\"test\", outfile=\"./prediction.txt\"):    \n",
        "    task.load_dataset(split=split, epoch=1)\n",
        "    itr = load_data_iterator(task, split, 1, config.max_tokens, config.num_workers).next_epoch_itr(shuffle=False)\n",
        "    \n",
        "    idxs = []\n",
        "    hyps = []\n",
        "\n",
        "    model.eval()\n",
        "    progress = tqdm.tqdm(itr, desc=f\"prediction\")\n",
        "    with torch.no_grad():\n",
        "        for i, sample in enumerate(progress):\n",
        "            # validation loss\n",
        "            sample = utils.move_to_cuda(sample, device=device)\n",
        "\n",
        "            # do inference\n",
        "            s, h, r = inference_step(sample, model)\n",
        "            \n",
        "            hyps.extend(h)\n",
        "            idxs.extend(list(sample['id']))\n",
        "            \n",
        "    # sort based on the order before preprocess\n",
        "    hyps = [x for _,x in sorted(zip(idxs,hyps))]\n",
        "    \n",
        "    with open(outfile, \"w\") as f:\n",
        "        for h in hyps:\n",
        "            f.write(h+\"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1z0cJE-wPzaU"
      },
      "source": [
        "# Back-translation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5-7uPJ2CP0sm"
      },
      "source": [
        "## Train a backward translation model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ppGHjg2ZP3sV"
      },
      "source": [
        "1. Switch the source_lang and target_lang in **config** \n",
        "2. Change the savedir in **config** (eg. \"./checkpoints/transformer-back\")\n",
        "3. Train model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "waTGz29UP6WI"
      },
      "source": [
        "## Generate synthetic data with backward model "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sIeTsPexP8FL"
      },
      "source": [
        "### Download monolingual data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "i7N4QlsbP8fh"
      },
      "outputs": [],
      "source": [
        "mono_dataset_name = 'mono'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "396saD9-QBPY"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ted_zh_corpus.deduped.gz is exist, skip downloading\n"
          ]
        }
      ],
      "source": [
        "mono_prefix = Path(data_dir).absolute() / mono_dataset_name\n",
        "mono_prefix.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "urls = (\n",
        "    \"https://github.com/yuhsinchan/ML2022-HW5Dataset/releases/download/v1.0.2/ted_zh_corpus.deduped.gz\",\n",
        ")\n",
        "file_names = (\n",
        "    'ted_zh_corpus.deduped.gz',\n",
        ")\n",
        "\n",
        "for u, f in zip(urls, file_names):\n",
        "    path = mono_prefix/f\n",
        "    if not path.exists():\n",
        "        !wget {u} -O {path}\n",
        "    else:\n",
        "        print(f'{f} is exist, skip downloading')\n",
        "    if path.suffix == \".tgz\":\n",
        "        !tar -xvf {path} -C {prefix}\n",
        "    elif path.suffix == \".zip\":\n",
        "        !unzip -o {path} -d {prefix}\n",
        "    elif path.suffix == \".gz\":\n",
        "        !gzip -fkd {path}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JOVQRHzGQU4-"
      },
      "source": [
        "### TODO: clean corpus\n",
        "\n",
        "1. remove sentences that are too long or too short\n",
        "2. unify punctuation\n",
        "\n",
        "hint: you can use clean_s() defined above to do this"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [],
      "source": [
        "def clean_mono_corpus(mono_prefix, l1, l2, max_len=1000, min_len=1):\n",
        "    if Path(f'{mono_prefix}/ted_zh_corpus.deduped.clean.{l1}').exists() and Path(f'{mono_prefix}/ted_zh_corpus.deduped.clean.{l2}').exists():\n",
        "        print(f'{mono_prefix}/ted_zh_corpus.deduped.clean.{l1} & {l2} exists. skipping clean.')\n",
        "        return\n",
        "    with open(f'{mono_prefix}/ted_zh_corpus.deduped', 'r') as l1_in_f:\n",
        "        with open(f'{mono_prefix}/ted_zh_corpus.deduped.clean.{l1}', 'w') as l1_out_f:\n",
        "            with open(f'{mono_prefix}/ted_zh_corpus.deduped.clean.{l2}', 'w') as l2_out_f:\n",
        "                for s1 in l1_in_f:\n",
        "                    s1 = s1.strip()\n",
        "                    s1 = clean_s(s1, l1)\n",
        "                    s1_len = len_s(s1, l1)\n",
        "                    if min_len > 0: # remove short sentence\n",
        "                        if s1_len < min_len:\n",
        "                            continue\n",
        "                    if max_len > 0: # remove long sentence\n",
        "                        if s1_len > max_len:\n",
        "                            continue\n",
        "                    print(s1, file=l1_out_f)\n",
        "                    print('.', file=l2_out_f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/home/weiweichi/weichi/HW5/DATA/rawdata/mono\n",
            "/home/weiweichi/weichi/HW5/DATA/rawdata/mono/ted_zh_corpus.deduped.clean.zh & en exists. skipping clean.\n"
          ]
        }
      ],
      "source": [
        "print(mono_prefix)\n",
        "clean_mono_corpus(mono_prefix, 'zh','en')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "非常謝謝你 , 克里斯 。 能有這個機會第二度踏上這個演講台\n",
            "真是一大榮幸 。 我非常感激 。\n",
            "這個研討會給我留下了極為深刻的印象 , 我想感謝大家對我之前演講的好評 。\n",
            "我是由衷的想這麼說 , 有部份原因是因為我真的有需要 !\n",
            "請你們設身處地為我想一想 !\n",
            "Thank you so much , Chris .\n",
            "And it's truly a great honor to have the opportunity to come to this stage twice ; I'm extremely grateful .\n",
            "I have been blown away by this conference , and I want to thank all of you for the many nice comments about what I had to say the other night .\n",
            "And I say that sincerely , partly because I need that .\n",
            "Put yourselves in my position .\n"
          ]
        }
      ],
      "source": [
        "!head {data_prefix+'.clean.'+'zh'} -n 5\n",
        "!head {data_prefix+'.clean.'+'en'} -n 5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jegH0bvMQVmR"
      },
      "source": [
        "### TODO: Subword Units\n",
        "\n",
        "Use the spm model of the backward model to tokenize the data into subword units\n",
        "\n",
        "hint: spm model is located at DATA/raw-data/\\[dataset\\]/spm\\[vocab_num\\].model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "vqgR4uUMQZGY"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/home/weiweichi/weichi/HW5/DATA/rawdata/mono/mono.tok.zh exists. skipping spm_encode.\n",
            "/home/weiweichi/weichi/HW5/DATA/rawdata/mono/mono.tok.en exists. skipping spm_encode.\n"
          ]
        }
      ],
      "source": [
        "for lang in ['zh', 'en']:\n",
        "    out_path = mono_prefix/f'mono.tok.{lang}'\n",
        "    if out_path.exists():\n",
        "        print(f\"{out_path} exists. skipping spm_encode.\")\n",
        "    else:\n",
        "        with open(mono_prefix/f'mono.tok.{lang}', 'w') as out_f:\n",
        "            with open(mono_prefix/f'ted_zh_corpus.deduped.clean.{lang}', 'r') as in_f:\n",
        "                for line in in_f:\n",
        "                    line = line.strip()\n",
        "                    tok = spm_model.encode(line, out_type=str)\n",
        "                    print(' '.join(tok), file=out_f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a65glBVXQZiE"
      },
      "source": [
        "### Binarize\n",
        "\n",
        "use fairseq to binarize data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "b803qA5aQaEu"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DATA/data-bin/mono exists, will not overwrite!\n"
          ]
        }
      ],
      "source": [
        "binpath = Path('./DATA/data-bin', mono_dataset_name)\n",
        "src_dict_file = './DATA/data-bin/ted2020/dict.en.txt'\n",
        "tgt_dict_file = src_dict_file\n",
        "monopref = str(mono_prefix/\"mono.tok\") # whatever filepath you get after applying subword tokenization\n",
        "if binpath.exists():\n",
        "    print(binpath, \"exists, will not overwrite!\")\n",
        "else:\n",
        "    !python3 -m fairseq_cli.preprocess\\\n",
        "        --source-lang 'zh'\\\n",
        "        --target-lang 'en'\\\n",
        "        --trainpref {monopref}\\\n",
        "        --destdir {binpath}\\\n",
        "        --srcdict {src_dict_file}\\\n",
        "        --tgtdict {tgt_dict_file}\\\n",
        "        --workers 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "smA0JraEQdxz"
      },
      "source": [
        "### TODO: Generate synthetic data with backward model\n",
        "\n",
        "Add binarized monolingual data to the original data directory, and name it with \"split_name\"\n",
        "\n",
        "ex. ./DATA/data-bin/ted2020/\\[split_name\\].zh-en.\\[\"en\", \"zh\"\\].\\[\"bin\", \"idx\"\\]\n",
        "\n",
        "then you can use 'generate_prediction(model, task, split=\"split_name\")' to generate translation prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "jvaOVHeoQfkB"
      },
      "outputs": [],
      "source": [
        "# Add binarized monolingual data to the original data directory, and name it with \"split_name\"\n",
        "# ex. ./DATA/data-bin/ted2020/\\[split_name\\].zh-en.\\[\"en\", \"zh\"\\].\\[\"bin\", \"idx\"\\]\n",
        "!cp ./DATA/data-bin/mono/train.zh-en.zh.bin ./DATA/data-bin/ted2020/mono.zh-en.zh.bin\n",
        "!cp ./DATA/data-bin/mono/train.zh-en.zh.idx ./DATA/data-bin/ted2020/mono.zh-en.zh.idx\n",
        "!cp ./DATA/data-bin/mono/train.zh-en.en.bin ./DATA/data-bin/ted2020/mono.zh-en.en.bin\n",
        "!cp ./DATA/data-bin/mono/train.zh-en.en.idx ./DATA/data-bin/ted2020/mono.zh-en.en.idx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "fFEkxPu-Qhlc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-04-05 11:58:30 | INFO | fairseq.data.data_utils | loaded 781,713 examples from: ./DATA/data-bin/ted2020/mono.zh-en.zh\n",
            "2022-04-05 11:58:30 | INFO | fairseq.data.data_utils | loaded 781,713 examples from: ./DATA/data-bin/ted2020/mono.zh-en.en\n",
            "2022-04-05 11:58:30 | INFO | fairseq.tasks.translation | ./DATA/data-bin/ted2020 mono zh-en 781713 examples\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "80c938b06f3b4c1ca3864b8f23ccc4dd",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "prediction:   0%|          | 0/1715 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# hint: do prediction on split='mono' to create prediction_file\n",
        "generate_prediction(model, task, split=\"mono\", outfile=\"./DATA/rawdata/mono/mono_prediction.txt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "in the mid16th century , italians were captivated by a kind of male singer whose incredible range contained notes previously thought impossible for adult men .\n",
            "but this gift came at a very high price .\n",
            "to prevent them from turning their voices , these singers were castrated before puberty , and they stopped hormonal changes so that their voices would sink beneath their voices .\n",
            "known as castrati , their light , angelic voices were renowned throughout europe , until this brutal process was banned in the 19th century .\n",
            "although the growth of the vocal folds can produce an extraordinary range , naturally developing voices have tremendous possibilities .\n"
          ]
        }
      ],
      "source": [
        "!head {'./DATA/rawdata/mono/mono_prediction.txt'} -n 5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jn4XeawpQjLk"
      },
      "source": [
        "### TODO: Create new dataset\n",
        "\n",
        "1. Combine the prediction data with monolingual data\n",
        "2. Use the original spm model to tokenize data into Subword Units\n",
        "3. Binarize data with fairseq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "3R35JTaTQjkm"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DATA/data-bin/synthetic exists, will not overwrite!\n"
          ]
        }
      ],
      "source": [
        "# Combine prediction_file (.en) and mono.zh (.zh) into a new dataset.\n",
        "# \n",
        "# hint: tokenize prediction_file with the spm model\n",
        "# spm_model.encode(line, out_type=str)\n",
        "# output: ./DATA/rawdata/mono/mono.tok.en & mono.tok.zh\n",
        "#\n",
        "# hint: use fairseq to binarize these two files again\n",
        "binpath = Path('./DATA/data-bin/synthetic')\n",
        "src_dict_file = './DATA/data-bin/ted2020/dict.en.txt'\n",
        "tgt_dict_file = src_dict_file\n",
        "monopref = './DATA/rawdata/mono/mono.tok' # or whatever path after applying subword tokenization, w/o the suffix (.zh/.en)\n",
        "if binpath.exists():\n",
        "    print(binpath, \"exists, will not overwrite!\")\n",
        "else:\n",
        "    !python3 -m fairseq_cli.preprocess\\\n",
        "        --source-lang 'zh'\\\n",
        "        --target-lang 'en'\\\n",
        "        --trainpref {monopref}\\\n",
        "        --destdir {binpath}\\\n",
        "        --srcdict {src_dict_file}\\\n",
        "        --tgtdict {tgt_dict_file}\\\n",
        "        --workers 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "MSkse1tyQnsR"
      },
      "outputs": [],
      "source": [
        "# create a new dataset from all the files prepared above\n",
        "!cp -r ./DATA/data-bin/ted2020/ ./DATA/data-bin/ted2020_with_mono/\n",
        "\n",
        "!cp ./DATA/data-bin/synthetic/train.zh-en.zh.bin ./DATA/data-bin/ted2020_with_mono/train1.en-zh.zh.bin\n",
        "!cp ./DATA/data-bin/synthetic/train.zh-en.zh.idx ./DATA/data-bin/ted2020_with_mono/train1.en-zh.zh.idx\n",
        "!cp ./DATA/data-bin/synthetic/train.zh-en.en.bin ./DATA/data-bin/ted2020_with_mono/train1.en-zh.en.bin\n",
        "!cp ./DATA/data-bin/synthetic/train.zh-en.en.idx ./DATA/data-bin/ted2020_with_mono/train1.en-zh.en.idx"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YVdxVGO3QrSs"
      },
      "source": [
        "Created new dataset \"ted2020_with_mono\"\n",
        "\n",
        "1. Change the datadir in **config** (\"./DATA/data-bin/ted2020_with_mono\")\n",
        "2. Switch back the source_lang and target_lang in **config** (\"en\", \"zh\")\n",
        "2. Change the savedir in **config** (eg. \"./checkpoints/transformer-bt\")\n",
        "3. Train model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_CZU2beUQtl3"
      },
      "source": [
        "1. <a name=ott2019fairseq></a>Ott, M., Edunov, S., Baevski, A., Fan, A., Gross, S., Ng, N., ... & Auli, M. (2019, June). fairseq: A Fast, Extensible Toolkit for Sequence Modeling. In Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics (Demonstrations) (pp. 48-53).\n",
        "2. <a name=vaswani2017></a>Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N., ... & Polosukhin, I. (2017, December). Attention is all you need. In Proceedings of the 31st International Conference on Neural Information Processing Systems (pp. 6000-6010).\n",
        "3. <a name=reimers-2020-multilingual-sentence-bert></a>Reimers, N., & Gurevych, I. (2020, November). Making Monolingual Sentence Embeddings Multilingual Using Knowledge Distillation. In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP) (pp. 4512-4525).\n",
        "4. <a name=tiedemann2012parallel></a>Tiedemann, J. (2012, May). Parallel Data, Tools and Interfaces in OPUS. In Lrec (Vol. 2012, pp. 2214-2218).\n",
        "5. <a name=kudo-richardson-2018-sentencepiece></a>Kudo, T., & Richardson, J. (2018, November). SentencePiece: A simple and language independent subword tokenizer and detokenizer for Neural Text Processing. In Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing: System Demonstrations (pp. 66-71).\n",
        "6. <a name=sennrich-etal-2016-improving></a>Sennrich, R., Haddow, B., & Birch, A. (2016, August). Improving Neural Machine Translation Models with Monolingual Data. In Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers) (pp. 86-96).\n",
        "7. <a name=edunov-etal-2018-understanding></a>Edunov, S., Ott, M., Auli, M., & Grangier, D. (2018). Understanding Back-Translation at Scale. In Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing (pp. 489-500).\n",
        "8. https://github.com/ajinkyakulkarni14/TED-Multilingual-Parallel-Corpus\n",
        "9. https://ithelp.ithome.com.tw/articles/10233122\n",
        "10. https://nlp.seas.harvard.edu/2018/04/03/attention.html\n",
        "11. https://colab.research.google.com/github/ga642381/ML2021-Spring/blob/main/HW05/HW05.ipynb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "Rrfm6iLJQ0tS"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-04-05 13:03:45 | ERROR | wandb.jupyter | Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "wandb: Currently logged in as: weiweichi (use `wandb login --relogin` to force relogin)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.12.11"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/home/weiweichi/weichi/HW5/wandb/run-20220405_130346-1fp0qalf</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/weiweichi/hw5.seq2seq/runs/1fp0qalf\" target=\"_blank\">transformer</a></strong> to <a href=\"https://wandb.ai/weiweichi/hw5.seq2seq\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "config = Namespace(\n",
        "    datadir = \"./DATA/data-bin/ted2020_with_mono\",\n",
        "    savedir = \"./checkpoints/transformer\",\n",
        "    source_lang = \"en\",\n",
        "    target_lang = \"zh\",\n",
        "    \n",
        "    # cpu threads when fetching & processing data.\n",
        "    num_workers=2,  \n",
        "    # batch size in terms of tokens. gradient accumulation increases the effective batchsize.\n",
        "    max_tokens=8192,\n",
        "    accum_steps=2,\n",
        "    \n",
        "    # the lr s calculated from Noam lr scheduler. you can tune the maximum lr by this factor.\n",
        "    lr_factor=2.,\n",
        "    lr_warmup=4000,\n",
        "    \n",
        "    # clipping gradient norm helps alleviate gradient exploding\n",
        "    clip_norm=1.0,\n",
        "    \n",
        "    # maximum epochs for training\n",
        "    max_epoch=35,\n",
        "    start_epoch=1,\n",
        "    \n",
        "    # beam size for beam search\n",
        "    beam=5, \n",
        "    # generate sequences of maximum length ax + b, where x is the source length\n",
        "    max_len_a=1.2, \n",
        "    max_len_b=10, \n",
        "    # when decoding, post process sentence by removing sentencepiece symbols and jieba tokenization.\n",
        "    post_process = \"sentencepiece\",\n",
        "    \n",
        "    # checkpoints\n",
        "    keep_last_epochs=5,\n",
        "    resume=None, # if resume from checkpoint name (under config.savedir)\n",
        "    \n",
        "    # logging\n",
        "    use_wandb=True,\n",
        ")\n",
        "if config.use_wandb:\n",
        "    import wandb\n",
        "    wandb.init(project=proj, name=Path(config.savedir).stem, config=config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-04-05 13:03:47 | INFO | fairseq.tasks.translation | [en] dictionary: 7992 types\n",
            "2022-04-05 13:03:47 | INFO | fairseq.tasks.translation | [zh] dictionary: 7992 types\n"
          ]
        }
      ],
      "source": [
        "task_cfg = TranslationConfig(\n",
        "    data=config.datadir,\n",
        "    source_lang=config.source_lang,\n",
        "    target_lang=config.target_lang,\n",
        "    train_subset=\"train\",\n",
        "    required_seq_len_multiple=8,\n",
        "    dataset_impl=\"mmap\",\n",
        "    upsample_primary=1,\n",
        ")\n",
        "task = TranslationTask.setup_task(task_cfg)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-04-05 13:03:47 | INFO | hw5.seq2seq | loading data for epoch 1\n",
            "2022-04-05 13:03:47 | INFO | fairseq.data.data_utils | loaded 390,041 examples from: ./DATA/data-bin/ted2020_with_mono/train.en-zh.en\n",
            "2022-04-05 13:03:47 | INFO | fairseq.data.data_utils | loaded 390,041 examples from: ./DATA/data-bin/ted2020_with_mono/train.en-zh.zh\n",
            "2022-04-05 13:03:47 | INFO | fairseq.tasks.translation | ./DATA/data-bin/ted2020_with_mono train en-zh 390041 examples\n",
            "2022-04-05 13:03:47 | INFO | fairseq.data.data_utils | loaded 781,713 examples from: ./DATA/data-bin/ted2020_with_mono/train1.en-zh.en\n",
            "2022-04-05 13:03:47 | INFO | fairseq.data.data_utils | loaded 781,713 examples from: ./DATA/data-bin/ted2020_with_mono/train1.en-zh.zh\n",
            "2022-04-05 13:03:47 | INFO | fairseq.tasks.translation | ./DATA/data-bin/ted2020_with_mono train1 en-zh 781713 examples\n",
            "2022-04-05 13:03:47 | INFO | fairseq.data.data_utils | loaded 3,939 examples from: ./DATA/data-bin/ted2020_with_mono/valid.en-zh.en\n",
            "2022-04-05 13:03:47 | INFO | fairseq.data.data_utils | loaded 3,939 examples from: ./DATA/data-bin/ted2020_with_mono/valid.en-zh.zh\n",
            "2022-04-05 13:03:47 | INFO | fairseq.tasks.translation | ./DATA/data-bin/ted2020_with_mono valid en-zh 3939 examples\n"
          ]
        }
      ],
      "source": [
        "logger.info(\"loading data for epoch 1\")\n",
        "task.load_dataset(split=\"train\", epoch=1, combine=True) # combine if you have back-translation data.\n",
        "task.load_dataset(split=\"valid\", epoch=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'id': 1,\n",
            " 'source': tensor([  35,   22,  440,   27,    5,  850,  261,  172,    6,   29,  800,    6,\n",
            "         184,  164,   99, 1178,  374,  804,  257,   41,    5,  313,  868,   42,\n",
            "          27,   61, 1836,   18,  184, 1147, 1404,   21,    6,    6,  320,    7,\n",
            "           2]),\n",
            " 'target': tensor([  53, 3134, 3107,   34,  408, 1223, 3895,  670,    9, 1038,  498,  148,\n",
            "        1689,  364,  129, 1050, 1103,   34,  408,  158,  607, 3268,  306,    9,\n",
            "        1105,    2])}\n",
            "('Source: so we bred flies whose brains were more or less randomly peppered '\n",
            " 'with cells that were light addressable .')\n",
            "'Target: 我們培植了一些果蠅它們的腦部被隨機地安置了一些可以光驅動的細胞'\n"
          ]
        }
      ],
      "source": [
        "sample = task.dataset(\"valid\")[1]\n",
        "pprint.pprint(sample)\n",
        "pprint.pprint(\n",
        "    \"Source: \" + \\\n",
        "    task.source_dictionary.string(\n",
        "        sample['source'],\n",
        "        config.post_process,\n",
        "    )\n",
        ")\n",
        "pprint.pprint(\n",
        "    \"Target: \" + \\\n",
        "    task.target_dictionary.string(\n",
        "        sample['target'],\n",
        "        config.post_process,\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-04-05 13:03:47 | WARNING | fairseq.tasks.fairseq_task | 2,565 samples have invalid sizes and will be skipped, max_positions=(20, 20), first few sample ids=[1643, 1630, 3670, 1642, 413, 2460, 3921, 681, 2996, 302]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'id': tensor([2710, 1186]),\n",
              " 'nsentences': 2,\n",
              " 'ntokens': 18,\n",
              " 'net_input': {'src_tokens': tensor([[  19,  269,   80,   31,   88,  617,    7,    2],\n",
              "          [  19,  185,   56,   18, 1119, 2760,    7,    2]]),\n",
              "  'src_lengths': tensor([8, 8]),\n",
              "  'prev_output_tokens': tensor([[   2,   40,  158, 1028,  336,  125,  444,  162,   10,    1,    1,    1,\n",
              "              1,    1,    1,    1],\n",
              "          [   2, 2375, 1979,  309, 2515,    9,  120,  782,   10,    1,    1,    1,\n",
              "              1,    1,    1,    1]])},\n",
              " 'target': tensor([[  40,  158, 1028,  336,  125,  444,  162,   10,    2,    1,    1,    1,\n",
              "             1,    1,    1,    1],\n",
              "         [2375, 1979,  309, 2515,    9,  120,  782,   10,    2,    1,    1,    1,\n",
              "             1,    1,    1,    1]])}"
            ]
          },
          "execution_count": 61,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "demo_epoch_obj = load_data_iterator(task, \"valid\", epoch=1, max_tokens=20, num_workers=1, cached=False)\n",
        "demo_iter = demo_epoch_obj.next_epoch_itr(shuffle=True)\n",
        "sample = next(demo_iter)\n",
        "sample"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {},
      "outputs": [],
      "source": [
        "arch_args = Namespace(\n",
        "    encoder_embed_dim=512,\n",
        "    encoder_ffn_embed_dim=2048,\n",
        "    encoder_layers=6,\n",
        "    decoder_embed_dim=512,\n",
        "    decoder_ffn_embed_dim=2048,\n",
        "    decoder_layers=6,\n",
        "    share_decoder_input_output_embed=True,\n",
        "    dropout=0.3,\n",
        ")\n",
        "\n",
        "def add_transformer_args(args):\n",
        "    args.encoder_attention_heads=8\n",
        "    args.encoder_normalize_before=True\n",
        "    \n",
        "    args.decoder_attention_heads=8\n",
        "    args.decoder_normalize_before=True\n",
        "    \n",
        "    args.activation_fn=\"relu\"\n",
        "    args.max_source_positions=1024\n",
        "    args.max_target_positions=1024\n",
        "    \n",
        "    # patches on default parameters for Transformer (those not set above)\n",
        "    from fairseq.models.transformer import base_architecture\n",
        "    base_architecture(arch_args)\n",
        "\n",
        "add_transformer_args(arch_args)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = build_model(arch_args, task)\n",
        "criterion = LabelSmoothedCrossEntropyCriterion(\n",
        "    smoothing=0.1,\n",
        "    ignore_index=task.target_dictionary.pad(),\n",
        ")\n",
        "optimizer = NoamOpt(\n",
        "    model_size=arch_args.encoder_embed_dim, \n",
        "    factor=config.lr_factor, \n",
        "    warmup=config.lr_warmup, \n",
        "    optimizer=torch.optim.AdamW(model.parameters(), lr=0, betas=(0.9, 0.98), eps=1e-9, weight_decay=0.0001)\n",
        ")\n",
        "sequence_generator = task.build_generator([model], config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = model.to(device=device)\n",
        "criterion = criterion.to(device=device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-04-05 13:03:49 | INFO | hw5.seq2seq | task: TranslationTask\n",
            "2022-04-05 13:03:49 | INFO | hw5.seq2seq | encoder: TransformerEncoder\n",
            "2022-04-05 13:03:49 | INFO | hw5.seq2seq | decoder: TransformerDecoder\n",
            "2022-04-05 13:03:49 | INFO | hw5.seq2seq | criterion: LabelSmoothedCrossEntropyCriterion\n",
            "2022-04-05 13:03:49 | INFO | hw5.seq2seq | optimizer: NoamOpt\n",
            "2022-04-05 13:03:49 | INFO | hw5.seq2seq | num. model params: 52,324,352 (num. trained: 52,324,352)\n",
            "2022-04-05 13:03:49 | INFO | hw5.seq2seq | max tokens per batch = 8192, accumulate steps = 2\n"
          ]
        }
      ],
      "source": [
        "logger.info(\"task: {}\".format(task.__class__.__name__))\n",
        "logger.info(\"encoder: {}\".format(model.encoder.__class__.__name__))\n",
        "logger.info(\"decoder: {}\".format(model.decoder.__class__.__name__))\n",
        "logger.info(\"criterion: {}\".format(criterion.__class__.__name__))\n",
        "logger.info(\"optimizer: {}\".format(optimizer.__class__.__name__))\n",
        "logger.info(\n",
        "    \"num. model params: {:,} (num. trained: {:,})\".format(\n",
        "        sum(p.numel() for p in model.parameters()),\n",
        "        sum(p.numel() for p in model.parameters() if p.requires_grad),\n",
        "    )\n",
        ")\n",
        "logger.info(f\"max tokens per batch = {config.max_tokens}, accumulate steps = {config.accum_steps}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-04-05 22:15:33 | INFO | hw5.seq2seq | training loss: 3.8386\n",
            "2022-04-05 22:15:33 | INFO | hw5.seq2seq | begin validation\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c72565d8acb04f44908db3fbdab8cf57",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "validation:   0%|          | 0/22 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-04-05 22:16:02 | INFO | hw5.seq2seq | example source: and in that sense of trying to get you out of your normal orbit , and to try to get you to pay attention to a story about someone who's given up smoking for the month of ramadan , she has to know something about a global audience .\n",
            "2022-04-05 22:16:02 | INFO | hw5.seq2seq | example hypothesis: 在那種情況下 , 試圖讓你脫離正常的軌道 , 試圖讓你關注一個故事 , 關於一個被放棄的拉瑪丹月份 , 她必須知道一個關於全球觀眾的故事 。\n",
            "2022-04-05 22:16:02 | INFO | hw5.seq2seq | example reference: 才能將身為聽眾的你拉出你的群落並試著讓你關注一個在回教齋月期間一個回民戒煙的故事她必須了解全球的聽眾\n",
            "2022-04-05 22:16:02 | INFO | hw5.seq2seq | validation loss:\t3.1111\n",
            "2022-04-05 22:16:02 | INFO | hw5.seq2seq | BLEU = 25.44 58.5/33.5/20.2/12.8 (BP = 0.954 ratio = 0.955 hyp_len = 106579 ref_len = 111605)\n",
            "2022-04-05 22:16:04 | INFO | hw5.seq2seq | saved epoch checkpoint: /home/weiweichi/weichi/HW5/checkpoints/transformer/checkpoint23.pt\n",
            "2022-04-05 22:16:06 | INFO | hw5.seq2seq | end of epoch 23\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1ea9a6af9c7647bcbf816e56bd07dec2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "train epoch 24:   0%|          | 0/1647 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-04-05 22:39:33 | INFO | hw5.seq2seq | training loss: 3.8339\n",
            "2022-04-05 22:39:33 | INFO | hw5.seq2seq | begin validation\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "de832267d97947cbafbb6a95efaf2cd7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "validation:   0%|          | 0/22 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-04-05 22:40:03 | INFO | hw5.seq2seq | example source: but we know that the proper study of mankind is man , to borrow from alexander pope .\n",
            "2022-04-05 22:40:03 | INFO | hw5.seq2seq | example hypothesis: 但我們知道人類正確的研究是人類 , 借用亞歷山大教授的話 。\n",
            "2022-04-05 22:40:03 | INFO | hw5.seq2seq | example reference: 不過我們知道正確的研究人類要用真人 , 我借用亞歷山大.波普的話 。\n",
            "2022-04-05 22:40:03 | INFO | hw5.seq2seq | validation loss:\t3.0989\n",
            "2022-04-05 22:40:03 | INFO | hw5.seq2seq | BLEU = 25.17 57.7/33.0/19.9/12.6 (BP = 0.959 ratio = 0.959 hyp_len = 107072 ref_len = 111605)\n",
            "2022-04-05 22:40:05 | INFO | hw5.seq2seq | saved epoch checkpoint: /home/weiweichi/weichi/HW5/checkpoints/transformer/checkpoint24.pt\n",
            "2022-04-05 22:40:05 | INFO | hw5.seq2seq | end of epoch 24\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2499a6e9f387474aa1bdf14ff353b609",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "train epoch 25:   0%|          | 0/1647 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-04-05 23:03:35 | INFO | hw5.seq2seq | training loss: 3.8236\n",
            "2022-04-05 23:03:35 | INFO | hw5.seq2seq | begin validation\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "396c8a90b8a94af980a36f11cf9da045",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "validation:   0%|          | 0/22 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-04-05 23:04:04 | INFO | hw5.seq2seq | example source: thank you .\n",
            "2022-04-05 23:04:04 | INFO | hw5.seq2seq | example hypothesis: 謝謝 。\n",
            "2022-04-05 23:04:04 | INFO | hw5.seq2seq | example reference: 謝謝 。\n",
            "2022-04-05 23:04:04 | INFO | hw5.seq2seq | validation loss:\t3.0971\n",
            "2022-04-05 23:04:04 | INFO | hw5.seq2seq | BLEU = 25.37 58.6/33.6/20.4/12.9 (BP = 0.945 ratio = 0.947 hyp_len = 105640 ref_len = 111605)\n",
            "2022-04-05 23:04:06 | INFO | hw5.seq2seq | saved epoch checkpoint: /home/weiweichi/weichi/HW5/checkpoints/transformer/checkpoint25.pt\n",
            "2022-04-05 23:04:06 | INFO | hw5.seq2seq | end of epoch 25\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7c6934a0028f4d82b5cb071c33c37d70",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "train epoch 26:   0%|          | 0/1647 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "epoch_itr = load_data_iterator(task, \"train\", config.start_epoch, config.max_tokens, config.num_workers)\n",
        "try_load_checkpoint(model, optimizer, name=config.resume)\n",
        "while epoch_itr.next_epoch_idx <= config.max_epoch:\n",
        "    # train for one epoch\n",
        "    train_one_epoch(epoch_itr, model, task, criterion, optimizer, config.accum_steps)\n",
        "    stats = validate_and_save(model, task, criterion, optimizer, epoch=epoch_itr.epoch)\n",
        "    logger.info(\"end of epoch {}\".format(epoch_itr.epoch))    \n",
        "    epoch_itr = load_data_iterator(task, \"train\", epoch_itr.next_epoch_idx, config.max_tokens, config.num_workers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Namespace(checkpoint_upper_bound=None, inputs=['./checkpoints/transformer'], num_epoch_checkpoints=5, num_update_checkpoints=None, output='./checkpoints/transformer/avg_last_5_checkpoint.pt')\n",
            "Traceback (most recent call last):\n",
            "  File \"./fairseq/scripts/average_checkpoints.py\", line 158, in <module>\n",
            "    main()\n",
            "  File \"./fairseq/scripts/average_checkpoints.py\", line 143, in main\n",
            "    args.inputs = last_n_checkpoints(\n",
            "  File \"./fairseq/scripts/average_checkpoints.py\", line 93, in last_n_checkpoints\n",
            "    raise Exception(\n",
            "Exception: ('Found {} checkpoint files but need at least {}', 1, 5)\n"
          ]
        }
      ],
      "source": [
        "# averaging a few checkpoints can have a similar effect to ensemble\n",
        "checkdir=config.savedir\n",
        "!python3 ./fairseq/scripts/average_checkpoints.py \\\n",
        "--inputs {checkdir} \\\n",
        "--num-epoch-checkpoints 5 \\\n",
        "--output {checkdir}/avg_last_5_checkpoint.pt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-04-05 04:55:19 | INFO | hw5.seq2seq | no checkpoints found at checkpoints/transformer/avg_last_5_checkpoint.pt!\n",
            "2022-04-05 04:55:19 | INFO | hw5.seq2seq | begin validation\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0831f11fb19143899f5949103ca84ab6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "validation:   0%|          | 0/22 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-04-05 04:55:54 | INFO | hw5.seq2seq | example source: i loved every minute of it .\n",
            "2022-04-05 04:55:54 | INFO | hw5.seq2seq | example hypothesis: 我聽過很多人 。\n",
            "2022-04-05 04:55:54 | INFO | hw5.seq2seq | example reference: 我愛那次演出的每一分鐘 。\n",
            "2022-04-05 04:55:54 | INFO | hw5.seq2seq | validation loss:\t4.8938\n",
            "2022-04-05 04:55:54 | INFO | hw5.seq2seq | BLEU = 4.20 23.6/6.6/2.3/0.9 (BP = 1.000 ratio = 1.028 hyp_len = 114702 ref_len = 111605)\n"
          ]
        }
      ],
      "source": [
        "try_load_checkpoint(model, name=\"avg_last_5_checkpoint.pt\")\n",
        "validate(model, task, criterion, log_to_wandb=False)\n",
        "None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-04-05 04:55:54 | INFO | fairseq.data.data_utils | loaded 4,000 examples from: ./DATA/data-bin/ted2020_with_mono/test.en-zh.en\n",
            "2022-04-05 04:55:54 | INFO | fairseq.data.data_utils | loaded 4,000 examples from: ./DATA/data-bin/ted2020_with_mono/test.en-zh.zh\n",
            "2022-04-05 04:55:54 | INFO | fairseq.tasks.translation | ./DATA/data-bin/ted2020_with_mono test en-zh 4000 examples\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ee99dcb4279d43309118f85eb4476b4d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "prediction:   0%|          | 0/17 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "generate_prediction(model, task, outfile=\"./prediction_bt.txt\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Report\n",
        "* Problem1: Visualize the similarity between different pairs of positional embedding and briefly explain the result.\n",
        "\n",
        "* Problem2: Clip gradient norm and visualize the changes of gradient norm in different steps. Circle two places with gradient explosion."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<AxesSubplot:>"
            ]
          },
          "execution_count": 71,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "pos_emb = model.decoder.embed_positions.weights.cpu().detach()\n",
        "cos = nn.CosineSimilarity(dim=0)\n",
        "n = pos_emb.size(0)\n",
        "similarity_m = np.zeros((n, n))\n",
        "\n",
        "for i in range(n):\n",
        "    for j in range(i, n):\n",
        "        cs = cos(pos_emb[i], pos_emb[j])\n",
        "        similarity_m[i][j] = similarity_m[j][i] = cs\n",
        "sns.heatmap(similarity_m, xticklabels=100, yticklabels=100)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "nKb4u67-sT_Z",
        "n1rwQysTsdJq",
        "59si_C0Wsms7",
        "oOpG4EBRLwe_",
        "6ZlE_1JnMv56",
        "UDAPmxjRNEEL",
        "ce5n4eS7NQNy",
        "rUB9f1WCNgMH",
        "VFJlkOMONsc6",
        "Gt1lX3DRO_yU",
        "BAGMiun8PnZy",
        "JOVQRHzGQU4-",
        "jegH0bvMQVmR",
        "a65glBVXQZiE",
        "smA0JraEQdxz",
        "Jn4XeawpQjLk"
      ],
      "name": "HW05.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
